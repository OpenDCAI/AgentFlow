[
    {
        "page_id": 0,
        "ocr_results": [
            {
                "block_id": 0,
                "type": "title",
                "bbox": [
                    640,
                    287,
                    1845,
                    427
                ],
                "angle": 0,
                "content": "COMET:Commonsense Transformers for Automatic Knowledge Graph Construction"
            },
            {
                "block_id": 1,
                "type": "text",
                "bbox": [
                    349,
                    491,
                    2160,
                    613
                ],
                "angle": 0,
                "content": "Antoine Bosselut \\(\\diamondsuit\\) Hannah Rashkin \\(\\diamondsuit\\) Maarten Sap \\(\\diamondsuit\\) Chaitanya Malaviya \\(\\diamondsuit\\) Asli Celikyilmaz \\(\\clubsuit\\) Yejin Choi \\(\\diamondsuit\\)"
            },
            {
                "block_id": 2,
                "type": "text",
                "bbox": [
                    632,
                    613,
                    1863,
                    673
                ],
                "angle": 0,
                "content": "\\(\\diamond\\)Allen Institute for Artificial Intelligence, Seattle, WA, USA"
            },
            {
                "block_id": 3,
                "type": "text",
                "bbox": [
                    451,
                    673,
                    2046,
                    792
                ],
                "angle": 0,
                "content": "\\(\\spadesuit\\)Paul G. Allen School of Computer Science & Engineering, Seattle, WA, USA  \n\\(\\clubsuit\\)Microsoft Research, Redmond, WA, USA"
            },
            {
                "block_id": 4,
                "type": "title",
                "bbox": [
                    654,
                    929,
                    850,
                    978
                ],
                "angle": 0,
                "content": "Abstract"
            },
            {
                "block_id": 5,
                "type": "text",
                "bbox": [
                    354,
                    1038,
                    1143,
                    2532
                ],
                "angle": 0,
                "content": "We present the first comprehensive study on automatic knowledge base construction for two prevalent commonsense knowledge graphs: ATOMIC (Sap et al., 2019) and ConceptNet (Speer et al., 2017). Contrary to many conventional KBs that store knowledge with canonical templates, commonsense KBs only store loosely structured open-text descriptions of knowledge. We posit that an important step toward automatic commonsense completion is the development of generative models of commonsense knowledge, and propose Commonsense Transformers (COMET) that learn to generate rich and diverse commonsense descriptions in natural language. Despite the challenges of commonsense modeling, our investigation reveals promising results when implicit knowledge from deep pre-trained language models is transferred to generate explicit knowledge in commonsense knowledge graphs. Empirical results demonstrate that COMET is able to generate novel knowledge that humans rate as high quality, with up to \\(77.5\\%\\) (ATOMIC) and \\(91.7\\%\\) (ConceptNet) precision at top 1, which approaches human performance for these resources. Our findings suggest that using generative commonsense models for automatic commonsense KB completion could soon be a plausible alternative to extractive methods."
            },
            {
                "block_id": 6,
                "type": "title",
                "bbox": [
                    290,
                    2588,
                    650,
                    2641
                ],
                "angle": 0,
                "content": "1 Introduction"
            },
            {
                "block_id": 7,
                "type": "text",
                "bbox": [
                    285,
                    2683,
                    1218,
                    3192
                ],
                "angle": 0,
                "content": "When reading text, humans make commonsense inferences that frame their understanding of the narrative being presented. For machines to achieve this capability, they must be able to acquire relevant and correct commonsense for an unbounded set of situations. In this work, we cast commonsense acquisition as knowledge base construction and investigate whether large-scale language models can effectively learn to generate the knowledge"
            },
            {
                "block_id": 8,
                "type": "image",
                "bbox": [
                    1285,
                    926,
                    2170,
                    1743
                ],
                "angle": 0,
                "content": null,
                "caption": "Figure 1: COMET learns from an existing knowledge base (solid lines) to be able to generate novel nodes and edges (dashed lines)."
            },
            {
                "block_id": 10,
                "type": "text",
                "bbox": [
                    1265,
                    2045,
                    2190,
                    2153
                ],
                "angle": 0,
                "content": "necessary to automatically construct a commonsense knowledge base (KB)."
            },
            {
                "block_id": 11,
                "type": "text",
                "bbox": [
                    1262,
                    2167,
                    2193,
                    3009
                ],
                "angle": 0,
                "content": "Automatic KB construction is a long-standing goal of artificial intelligence research due to the difficulty of achieving high concept coverage in high-precision curated KBs (Lenat, 1995; Miller, 1995). Previous work has developed models capable of reading and extracting semi-structured text (Suchanek et al., 2007; Hoffart et al., 2013; Auer et al., 2007; Bollacker et al., 2008) and unstructured text (Dong et al., 2014; Carlson et al., 2010; Nakashole et al., 2011, 2012; Niu, 2012) into relational schemas that can be queried for downstream applications. A common thread of these approaches, however, is the focus on encyclopedic knowledge, which lends itself to a well-defined space of entities and relations that can be modeled."
            },
            {
                "block_id": 12,
                "type": "text",
                "bbox": [
                    1265,
                    3023,
                    2193,
                    3192
                ],
                "angle": 0,
                "content": "Commonsense knowledge, however, does not cleanly fit into a schema comparing two entities with a known relation, leading current approaches"
            },
            {
                "block_id": 13,
                "type": "page_number",
                "bbox": [
                    1190,
                    3230,
                    1292,
                    3279
                ],
                "angle": 0,
                "content": "4762"
            },
            {
                "block_id": 14,
                "type": "footer",
                "bbox": [
                    416,
                    3301,
                    2056,
                    3399
                ],
                "angle": 0,
                "content": "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 4762-4779 Florence, Italy, July 28 - August 2, 2019. ©2019 Association for Computational Linguistics"
            }
        ]
    },
    {
        "page_id": 1,
        "ocr_results": [
            {
                "block_id": 0,
                "type": "image",
                "bbox": [
                    439,
                    277,
                    890,
                    919
                ],
                "angle": 0,
                "content": null,
                "caption": "(a)"
            },
            {
                "block_id": 2,
                "type": "image",
                "bbox": [
                    895,
                    277,
                    1309,
                    922
                ],
                "angle": 0,
                "content": null,
                "caption": "(b)"
            },
            {
                "block_id": 4,
                "type": "image",
                "bbox": [
                    1309,
                    280,
                    2054,
                    922
                ],
                "angle": 0,
                "content": null,
                "caption": "(c)"
            },
            {
                "block_id": 6,
                "type": "image_caption",
                "bbox": [
                    285,
                    999,
                    2198,
                    1304
                ],
                "angle": 0,
                "content": "Figure 2: Model diagram. (a) In the multi-headed attention module, the key, value, and query all pass through a head-specific projection before a scaled dot-product attention is computed between them. The outputs of the heads are concatenated and projected. (b) Inside the transformer block, the outputs of all the previous layer blocks from earlier time steps are input to the multi-headed attention with the preceding block for the current time step as the query. (c) Each token is an input to a first-layer block along with all preceding tokens. Dotted lines indicate outputs to all future blocks in the next layer and inputs from all preceding blocks in the previous layer."
            },
            {
                "block_id": 7,
                "type": "text",
                "bbox": [
                    285,
                    1392,
                    1213,
                    1953
                ],
                "angle": 0,
                "content": "to model \"entities\" as natural language phrases and relations as any concept that can link them (Li et al., 2016; Sap et al., 2019). OpenIE approaches display this property of open text entities and relations (Etzioni et al., 2011; Fader et al., 2011; Mausam et al., 2012), but being extractive, they only capture knowledge that is explicitly mentioned in text, limiting their applicability for capturing commonsense knowledge, which is often implicit (Gordon and Van Durme, 2013)."
            },
            {
                "block_id": 8,
                "type": "text",
                "bbox": [
                    285,
                    1982,
                    1215,
                    2943
                ],
                "angle": 0,
                "content": "Meanwhile, recent progress in training deep contextualized language models (Peters et al., 2018; Radford et al., 2018; Devlin et al., 2018) provides an opportunity to explore beyond extractive methods as an avenue for commonsense KB construction. These large-scale language models display impressive performance when their underlying representations are tuned to solve end tasks, achieving state-of-the-art results on a variety of complex problems. In this work, we define the CommonsEnse Transformer (COMET), which constructs commonsense KBs by using existing tuples as a seed set of knowledge on which to train. Using this seed set, a pre-trained language model learns to adapt its learned representations to knowledge generation, and produces novel tuples that are high quality."
            },
            {
                "block_id": 9,
                "type": "text",
                "bbox": [
                    285,
                    2967,
                    1215,
                    3192
                ],
                "angle": 0,
                "content": "We summarize our contributions in this work as follows. First, we develop a generative approach to knowledge base construction. A model must learn to produce new nodes and identify edges be"
            },
            {
                "block_id": 10,
                "type": "text",
                "bbox": [
                    1265,
                    1392,
                    2195,
                    2290
                ],
                "angle": 0,
                "content": "tween existing nodes by generating phrases that coherently complete an existing seed phrase and relation type<sup>1</sup>. Second, we develop a framework for using large-scale transformer language models to learn to produce commonsense knowledge tuples<sup>2</sup>. Finally, we perform an empirical study on the quality, novelty, and diversity of the commonsense knowledge produced by our approach for two domains, ATOMIC and ConceptNet, as well as an efficiency study on the number of seed tuples needed to learn an effective knowledge model. The results indicate that COMET is able to produce high quality tuples as human judges find that \\(77.5\\%\\) of generated tuples for ATOMIC events and \\(91.7\\%\\) of generated tuples for ConceptNet relations are correct."
            },
            {
                "block_id": 11,
                "type": "title",
                "bbox": [
                    1267,
                    2353,
                    2138,
                    2409
                ],
                "angle": 0,
                "content": "2 Learning to Generate Commonsense"
            },
            {
                "block_id": 12,
                "type": "text",
                "bbox": [
                    1265,
                    2455,
                    2195,
                    2960
                ],
                "angle": 0,
                "content": "COMET is an adaptation framework for constructing commonsense knowledge bases from language models by training the language model on a seed set of knowledge tuples. These tuples provide COMET with the KB structure and relations that must be learned, and COMET learns to adapt the language model representations learned from pretraining to add novel nodes and edges to the seed knowledge graph."
            },
            {
                "block_id": 13,
                "type": "page_footnote",
                "bbox": [
                    1267,
                    3013,
                    2188,
                    3097
                ],
                "angle": 0,
                "content": "\\(^{1}\\)Demo is available at https://mosaickg.apps. allenai.org/"
            },
            {
                "block_id": 14,
                "type": "page_footnote",
                "bbox": [
                    1272,
                    3101,
                    2188,
                    3185
                ],
                "angle": 0,
                "content": "\\(^{2}\\)Code is available at https://github.com/atcbosselut/comet-commonsense"
            },
            {
                "block_id": 15,
                "type": "list",
                "bbox": [
                    1267,
                    3013,
                    2188,
                    3185
                ],
                "angle": 0,
                "content": null
            },
            {
                "block_id": 16,
                "type": "page_number",
                "bbox": [
                    1193,
                    3230,
                    1292,
                    3279
                ],
                "angle": 0,
                "content": "4763"
            }
        ]
    },
    {
        "page_id": 2,
        "ocr_results": [
            {
                "block_id": 0,
                "type": "title",
                "bbox": [
                    287,
                    266,
                    498,
                    312
                ],
                "angle": 0,
                "content": "2.1 Task"
            },
            {
                "block_id": 1,
                "type": "text",
                "bbox": [
                    285,
                    343,
                    1215,
                    855
                ],
                "angle": 0,
                "content": "More specifically, the problem assumes \\(\\mathbb{C}\\mathsf{OMET}\\) is given a training knowledge base of natural language tuples in \\(\\{s,r,o\\}\\) format, where \\(s\\) is the phrase subject of the tuple, \\(r\\) is the relation of the tuple, and \\(o\\) is the phrase object of the tuple. For example, a ConceptNet tuple relating to \"taking a nap\" would be: (\\(s=\\) \"take a nap\", \\(r=\\) Causes, \\(o=\\) \"have energy\"). The task is to generate \\(o\\) given \\(s\\) and \\(r\\) as inputs."
            },
            {
                "block_id": 2,
                "type": "text",
                "bbox": [
                    287,
                    898,
                    1215,
                    1245
                ],
                "angle": 0,
                "content": "Notation We define \\( X^{s} = \\{x_{0}^{s},\\ldots ,x_{|s|}^{s}\\} \\) as the tokens that make up the subject of the relation, \\( X^{r} = \\{x_{0}^{r},\\dots,x_{|r|}^{r}\\} \\) as the tokens that make up the relation of the tuple, and \\( X^{o} = \\{x_{0}^{o},\\dots,x_{|o|}^{o}\\} \\) as the tokens that make up the object of the tuple. The embedding for any word \\( x \\) is denoted as \\( e \\)."
            },
            {
                "block_id": 3,
                "type": "title",
                "bbox": [
                    287,
                    1301,
                    997,
                    1357
                ],
                "angle": 0,
                "content": "2.2 Transformer Language Model"
            },
            {
                "block_id": 4,
                "type": "text",
                "bbox": [
                    285,
                    1378,
                    1215,
                    1943
                ],
                "angle": 0,
                "content": "While COMET is agnostic to the language model with which it is initialized, in this work, we use the transformer language model architecture introduced in Radford et al. (2018) (GPT), which uses multiple transformer blocks of multi-headed scaled dot product attention and fully connected layers to encode input text (Vaswani et al., 2017). Figure 2 depicts different components of the GPT architecture and we define each component in more depth below."
            },
            {
                "block_id": 5,
                "type": "text",
                "bbox": [
                    285,
                    1992,
                    1215,
                    2273
                ],
                "angle": 0,
                "content": "Transformer Block As shown in Figure 2(b), each transformer layer \\(l\\) contains an architecturally identical transformer block (though with unique trainable parameters) that applies the following transformations to the input to the block:"
            },
            {
                "block_id": 6,
                "type": "equation",
                "bbox": [
                    458,
                    2325,
                    1210,
                    2395
                ],
                "angle": 0,
                "content": "\\[\n\\tilde {g} ^ {l} = \\mathbf {M u l t i A T T N} \\left(h ^ {l - 1}\\right) \\tag {1}\n\\]"
            },
            {
                "block_id": 7,
                "type": "equation",
                "bbox": [
                    458,
                    2402,
                    1210,
                    2469
                ],
                "angle": 0,
                "content": "\\[\ng ^ {l} = \\operatorname {L A Y E R N O R M} \\left(\\tilde {g} ^ {l} + h ^ {l - 1}\\right) \\tag {2}\n\\]"
            },
            {
                "block_id": 8,
                "type": "equation",
                "bbox": [
                    458,
                    2480,
                    1210,
                    2546
                ],
                "angle": 0,
                "content": "\\[\n\\tilde {h} ^ {l} = \\operatorname {F F N} (g ^ {l}) \\tag {3}\n\\]"
            },
            {
                "block_id": 9,
                "type": "equation",
                "bbox": [
                    458,
                    2553,
                    1210,
                    2620
                ],
                "angle": 0,
                "content": "\\[\nh ^ {l} = \\operatorname {L A Y E R N O R M} \\left(\\tilde {h} ^ {l} + g ^ {l}\\right) \\tag {4}\n\\]"
            },
            {
                "block_id": 10,
                "type": "text",
                "bbox": [
                    285,
                    2683,
                    1218,
                    3192
                ],
                "angle": 0,
                "content": "where MULTIATTN is a multi-headed self-attention mechanism (defined below), FFN is a two-layer feed-forward network, and LAYER-NORM represents a layer normalization (Ba et al., 2016) operation that is applied to the output of the self-attention and the feedforward network. Note that the inputs to the LAYER-NORM operations contain a residual connection that sums the output of and input to the previous operation."
            },
            {
                "block_id": 11,
                "type": "text",
                "bbox": [
                    1265,
                    263,
                    2195,
                    715
                ],
                "angle": 0,
                "content": "Multi-headed Attention The multi-headed attention module of each transformer block, shown in Figure 2(a), is identical to the one originally defined by Vaswani et al. (2017). The attention function receives three inputs, a query \\( Q \\), key \\( K \\), and value \\( V \\). The attention is made of multiple heads that each compute a unique scaled dot product attention distribution over \\( V \\) using \\( Q \\) and \\( K \\):"
            },
            {
                "block_id": 12,
                "type": "equation",
                "bbox": [
                    1302,
                    750,
                    2193,
                    933
                ],
                "angle": 0,
                "content": "\\[\n\\operatorname {A T T E N T I O N} (Q, K, V) = \\operatorname {s o f t m a x} \\left(\\frac {Q K ^ {T}}{\\sqrt {d _ {k}}}\\right) V \\tag {5}\n\\]"
            },
            {
                "block_id": 13,
                "type": "text",
                "bbox": [
                    1265,
                    975,
                    2195,
                    1203
                ],
                "angle": 0,
                "content": "where \\( d_{k} \\) is the dimensionality of the input vectors representing the query, key and value. For each of the heads, \\( Q \\), \\( K \\), and \\( V \\) are uniquely projected prior to the attention being computed:"
            },
            {
                "block_id": 14,
                "type": "equation",
                "bbox": [
                    1312,
                    1238,
                    2193,
                    1308
                ],
                "angle": 0,
                "content": "\\[\nH _ {i} = \\mathrm {A T T E N T I O N} \\left(Q W _ {i} ^ {Q}, K W _ {i} ^ {K}, V W _ {i} ^ {V}\\right) \\tag {6}\n\\]"
            },
            {
                "block_id": 15,
                "type": "text",
                "bbox": [
                    1265,
                    1350,
                    2193,
                    1575
                ],
                "angle": 0,
                "content": "where \\(H_{i}\\) is the output of a single attention head and \\(W_{i}^{Q}, W_{i}^{K}\\), and \\(W_{i}^{V}\\) are head-specific projections for \\(Q, K\\), and \\(V\\), respectively. The outputs of the attention heads \\(H_{i}\\) are then concatenated:"
            },
            {
                "block_id": 16,
                "type": "equation",
                "bbox": [
                    1339,
                    1617,
                    2193,
                    1683
                ],
                "angle": 0,
                "content": "\\[\n\\mathbf {M u l t i H} (\\mathbf {Q}, \\mathbf {K}, \\mathbf {V}) = [ H _ {1}; \\dots ; H _ {b} ] W ^ {O} \\qquad (7)\n\\]"
            },
            {
                "block_id": 17,
                "type": "text",
                "bbox": [
                    1265,
                    1722,
                    2193,
                    2178
                ],
                "angle": 0,
                "content": "where \\( W^{O} \\) is an output projection of the concatenated outputs of the attention heads. As shown in Figure 2(c), we follow Radford et al. (2018) and use the output of the previous layer's transformer block as the query input for the multi-headed attention of the next block. The keys and values are outputs of the previous layer's block for all preceding time steps:"
            },
            {
                "block_id": 18,
                "type": "equation",
                "bbox": [
                    1267,
                    2213,
                    2200,
                    2336
                ],
                "angle": 0,
                "content": "\\[\n\\operatorname {M u l t i A T T N} \\left(h _ {t} ^ {l - 1}\\right) = \\operatorname {M u l t i H} \\left(h _ {t} ^ {l - 1}, \\mathbf {h} _ {t} ^ {l - 1}, \\mathbf {h} _ {t} ^ {l - 1}\\right) \\tag {8}\n\\]"
            },
            {
                "block_id": 19,
                "type": "text",
                "bbox": [
                    1265,
                    2381,
                    2193,
                    2560
                ],
                "angle": 0,
                "content": "where \\(\\mathbf{h}_t^{l-1} = \\{h^{l-1}\\}_{<t}\\) is the set of previous layer transformer block outputs for time steps preceding \\(t\\)."
            },
            {
                "block_id": 20,
                "type": "text",
                "bbox": [
                    1265,
                    2592,
                    2193,
                    2760
                ],
                "angle": 0,
                "content": "Input Encoder As input to the model, we represent a knowledge tuple \\(\\{s,r,o\\}\\) as a concatenated sequence of the words of each item of the tuple:"
            },
            {
                "block_id": 21,
                "type": "equation",
                "bbox": [
                    1540,
                    2802,
                    2190,
                    2866
                ],
                "angle": 0,
                "content": "\\[\n\\mathbf {X} = \\left\\{X ^ {s}, X ^ {r}, X ^ {o} \\right\\} \\tag {9}\n\\]"
            },
            {
                "block_id": 22,
                "type": "text",
                "bbox": [
                    1265,
                    2911,
                    2193,
                    3192
                ],
                "angle": 0,
                "content": "Since the transformer (a self-attention model) has no concept of ordering of tokens, a position embedding \\( p_t \\) is initialized for each absolute position in the sequence (Vaswani et al., 2017). For any input word \\( x_t \\in \\mathbf{X} \\), our encoding of the input is"
            },
            {
                "block_id": 23,
                "type": "page_number",
                "bbox": [
                    1193,
                    3230,
                    1292,
                    3276
                ],
                "angle": 0,
                "content": "4764"
            }
        ]
    },
    {
        "page_id": 3,
        "ocr_results": [
            {
                "block_id": 1,
                "type": "table",
                "bbox": [
                    317,
                    315,
                    1185,
                    417
                ],
                "angle": 0,
                "content": "<table><tr><td>s tokens</td><td>mask tokens</td><td>r token</td><td>o tokens</td></tr><tr><td colspan=\"4\">PersonX goes to the mall [MASK] &lt;xIntent&gt; to buy clothes</td></tr></table>",
                "caption": "ConceptNet Relation to Language Input Template"
            },
            {
                "block_id": 3,
                "type": "table",
                "bbox": [
                    317,
                    480,
                    1185,
                    589
                ],
                "angle": 0,
                "content": "<table><tr><td>s tokens</td><td>mask tokens</td><td>r tokens</td><td>mask tokens</td><td>o tokens</td></tr><tr><td colspan=\"5\">go to mall [MASK] [MASK] has prerequisite [MASK] have money</td></tr></table>"
            },
            {
                "block_id": 4,
                "type": "text",
                "bbox": [
                    285,
                    634,
                    1215,
                    1083
                ],
                "angle": 0,
                "content": "Figure 3: Input token setup for training configurations. For the ATOMIC dataset, the tokens of the subject, \\( X^s \\) (e.g., PersonX goes to the mall) are followed by masking tokens, which is followed by a single relation token \\( X^r \\) (e.g., xIntent), and then the object tokens \\( X^o \\) (e.g., to buy clothes). The model receives the same input for ConceptNet, except that a second set of masking tokens separate \\( X^r \\) and \\( X^o \\) because \\( X^r \\) can have a variable number of tokens for ConceptNet (§5.2)"
            },
            {
                "block_id": 5,
                "type": "text",
                "bbox": [
                    285,
                    1171,
                    1213,
                    1336
                ],
                "angle": 0,
                "content": "the sum of its word embedding, \\( e_t \\) with a position embedding encoding its absolute position in the sequence \\( \\mathbf{X} \\):"
            },
            {
                "block_id": 6,
                "type": "equation",
                "bbox": [
                    625,
                    1389,
                    1210,
                    1455
                ],
                "angle": 0,
                "content": "\\[\nh _ {t} ^ {0} = e _ {t} + p _ {t} \\tag {10}\n\\]"
            },
            {
                "block_id": 7,
                "type": "text",
                "bbox": [
                    287,
                    1476,
                    1213,
                    1589
                ],
                "angle": 0,
                "content": "where \\( p_t \\) is the position embedding for time step \\( t \\), and \\( h^0 \\) is the input to the first transformer layer."
            },
            {
                "block_id": 8,
                "type": "title",
                "bbox": [
                    287,
                    1627,
                    731,
                    1687
                ],
                "angle": 0,
                "content": "3 Training COMET"
            },
            {
                "block_id": 9,
                "type": "text",
                "bbox": [
                    285,
                    1715,
                    1215,
                    2108
                ],
                "angle": 0,
                "content": "COMET is trained to learn to produce the phrase object \\(o\\) of a knowledge tuple given the tuple's phrase subject \\(s\\) and relation \\(r\\). More specifically, given the concatenation of the tokens of \\(s\\) and \\(r\\): \\([X^s, X^r]\\) as input, the model must learn to generate the tokens of \\(o\\): \\(X^o\\) (See §2.1 for definitions of these variables)."
            },
            {
                "block_id": 10,
                "type": "text",
                "bbox": [
                    285,
                    2139,
                    1213,
                    2311
                ],
                "angle": 0,
                "content": "Loss Function To achieve this goal, \\(\\mathbb{COMET}\\) is trained to maximize the conditional loglikelihood of predicting the phrase object tokens, \\(X^o\\):"
            },
            {
                "block_id": 11,
                "type": "equation",
                "bbox": [
                    458,
                    2353,
                    1210,
                    2522
                ],
                "angle": 0,
                "content": "\\[\n\\mathcal {L} = - \\sum_ {t = | s | + | r |} ^ {| s | + | r | + | o |} \\log P (x _ {t} | x _ {<   t}) \\tag {11}\n\\]"
            },
            {
                "block_id": 12,
                "type": "text",
                "bbox": [
                    285,
                    2539,
                    1213,
                    2767
                ],
                "angle": 0,
                "content": "where \\( |s|, |r| \\), and \\( |o| \\) are the number of tokens in the subject phrase, relation, and object phrase, respectively. Figure 3 outlines how the tokens in \\( s \\), \\( r \\), and \\( o \\) are organized for different training tasks."
            },
            {
                "block_id": 13,
                "type": "text",
                "bbox": [
                    285,
                    2795,
                    1215,
                    3192
                ],
                "angle": 0,
                "content": "Datasets \\(\\mathbb{C}\\) oMET relies on a seed set of knowledge tuples from an existing KB to learn to produce commonsense knowledge. In this work, we use ATOMIC and ConceptNet as knowledge seed sets, but other commonsense knowledge resources could have been used as well as \\(\\mathbb{C}\\) oMET is domain-agnostic."
            },
            {
                "block_id": 14,
                "type": "text",
                "bbox": [
                    1265,
                    263,
                    2193,
                    655
                ],
                "angle": 0,
                "content": "Initialization Parameters are initialized to the final language model weights from Radford et al. (2018). Additional special tokens that are added to the vocabulary for fine tuning (e.g., relation embeddings such as oReact for ATOMIC and Isa for ConceptNet) are initialized by sampling from the standard normal distribution."
            },
            {
                "block_id": 15,
                "type": "text",
                "bbox": [
                    1265,
                    691,
                    2193,
                    1143
                ],
                "angle": 0,
                "content": "Hyperparameters Following Radford et al. (2018)'s design of the GPT model, we initialize COMET with 12 layers, 768-dimensional hidden states, and 12 attention heads. We use a dropout rate of 0.1 and use GeLU (Hendrycks and Gimpel, 2016) units as activation functions. During training, our batch size is 64. Other dataset-specific hyperparameters are provided in Appendix A.1."
            },
            {
                "block_id": 16,
                "type": "title",
                "bbox": [
                    1267,
                    1185,
                    1826,
                    1241
                ],
                "angle": 0,
                "content": "4 ATOMIC Experiments"
            },
            {
                "block_id": 17,
                "type": "text",
                "bbox": [
                    1262,
                    1273,
                    2193,
                    2234
                ],
                "angle": 0,
                "content": "The ATOMIC dataset<sup>3</sup>, released by Sap et al. (2019), contains 877K tuples covering a variety of social commonsense knowledge around specific event prompts (e.g., \"X goes to the store\"). Specifically, ATOMIC distills its commonsense in nine dimensions, covering the event's causes (e.g., \"X needs to drive there\"), its effects on the agent (e.g., \"to get food\") and its effect on other direct (or implied) participants (e.g., \"Others will be fed\"). More details about ATOMIC can be found in Appendix D. For our experiments, ATOMIC events (e.g., \"X goes to the store\") are phrase subjects, \\(s\\), the dimension (e.g., xIntent) is the phrase relation, \\(r\\), and the causes/effects (e.g., \"to get food\") are phrase objects, \\(o\\). We use the training splits from Sap et al. (2019), resulting in 710k training, 80k development, and 87k test tuples respectively."
            },
            {
                "block_id": 18,
                "type": "title",
                "bbox": [
                    1267,
                    2273,
                    1498,
                    2329
                ],
                "angle": 0,
                "content": "4.1 Setup"
            },
            {
                "block_id": 19,
                "type": "text",
                "bbox": [
                    1265,
                    2346,
                    2193,
                    3023
                ],
                "angle": 0,
                "content": "Metrics Following Sap et al. (2019), we evaluate our method using BLEU-2 as an automatic evaluation metric. We also report the perplexity of the model on its gold generations. The remaining automatic metrics in Table 1 measure the proportion of generated tuples and generated objects which are not in the training set. We report the proportion of all generated tuples that are novel (\\% N/T sro) and that have a novel object (\\% N/T o)\\(^4\\). To show that these novel objects are diverse (i.e., the same novel object is not the only one being generated), we also report the number of novel"
            },
            {
                "block_id": 20,
                "type": "page_footnote",
                "bbox": [
                    1267,
                    3051,
                    2168,
                    3192
                ],
                "angle": 0,
                "content": "3https://homes.cs.washington.edu/ \\~msap/atomic/ a new o represents a new node in the knowledge graph"
            },
            {
                "block_id": 21,
                "type": "page_number",
                "bbox": [
                    1193,
                    3230,
                    1292,
                    3279
                ],
                "angle": 0,
                "content": "4765"
            }
        ]
    },
    {
        "page_id": 4,
        "ocr_results": [
            {
                "block_id": 0,
                "type": "table",
                "bbox": [
                    491,
                    256,
                    2004,
                    694
                ],
                "angle": 0,
                "content": "<table><tr><td>Model</td><td>PPL5</td><td>BLEU-2</td><td>N/T sro6</td><td>N/T o</td><td>N/U o</td></tr><tr><td>9ENC9DEC (Sap et al., 2019)</td><td>-</td><td>10.01</td><td>100.00</td><td>8.61</td><td>40.77</td></tr><tr><td>NearestNeighbor (Sap et al., 2019)</td><td>-</td><td>6.61</td><td>-</td><td>-</td><td>-</td></tr><tr><td>Event2(IN)VOLUN (Sap et al., 2019)</td><td>-</td><td>9.67</td><td>100.00</td><td>9.52</td><td>45.06</td></tr><tr><td>Event2PERSONX/Y (Sap et al., 2019)</td><td>-</td><td>9.24</td><td>100.00</td><td>8.22</td><td>41.66</td></tr><tr><td>Event2PRE/POST (Sap et al., 2019)</td><td>-</td><td>9.93</td><td>100.00</td><td>7.38</td><td>41.99</td></tr><tr><td>COMET (- pretrain)</td><td>15.42</td><td>13.88</td><td>100.00</td><td>7.25</td><td>45.71</td></tr><tr><td>COMET</td><td>11.14</td><td>15.10</td><td>100.00</td><td>9.71</td><td>51.20</td></tr></table>",
                "caption": "Table 1: Automatic evaluations of quality and novelty for generations of ATOMIC commonsense. No novelty scores are reported for the NearestNeighbor baseline because all retrieved sequences are in the training set."
            },
            {
                "block_id": 2,
                "type": "table",
                "bbox": [
                    297,
                    869,
                    2198,
                    1231
                ],
                "angle": 0,
                "content": "<table><tr><td>Model</td><td>oEffect</td><td>oReact</td><td>oWant</td><td>xAttr</td><td>xEffect</td><td>xIntent</td><td>xNeed</td><td>xReact</td><td>xWant</td><td>Avg</td></tr><tr><td>9Enc9Dec (Sap et al., 2019)</td><td>22.92</td><td>32.92</td><td>35.50</td><td>52.20</td><td>47.52</td><td>51.70</td><td>48.74</td><td>63.57</td><td>51.56</td><td>45.32</td></tr><tr><td>Event2(In)voluntary (Sap et al., 2019)</td><td>26.46</td><td>36.04</td><td>34.70</td><td>52.58</td><td>46.76</td><td>61.32</td><td>49.82</td><td>71.22</td><td>52.44</td><td>47.93</td></tr><tr><td>Event2PersonX/Y (Sap et al., 2019)</td><td>24.72</td><td>33.80</td><td>35.08</td><td>52.98</td><td>48.86</td><td>53.93</td><td>54.05</td><td>66.42</td><td>54.04</td><td>46.41</td></tr><tr><td>Event2Pre/Post (Sap et al., 2019)</td><td>26.26</td><td>34.48</td><td>35.78</td><td>52.20</td><td>46.78</td><td>57.77</td><td>47.94</td><td>72.22</td><td>47.94</td><td>46.76</td></tr><tr><td>COMET (- pretrain)</td><td>25.90</td><td>35.40</td><td>40.76</td><td>48.04</td><td>47.20</td><td>58.88</td><td>59.16</td><td>64.52</td><td>65.66</td><td>49.50</td></tr><tr><td>COMET</td><td>29.02</td><td>37.68</td><td>44.48</td><td>57.48</td><td>55.50</td><td>68.32</td><td>64.24</td><td>76.18</td><td>75.16</td><td>56.45</td></tr></table>",
                "caption": "Table 2: Human score of generations of ATOMIC commonsense. We present comparisons to the baselines from Sap et al. (2019). Underlined results are those where \\(\\mathbb{C}\\mathbb{O}\\mathbb{M}\\mathbb{T}\\) is not significantly better at \\(p < 0.05\\)"
            },
            {
                "block_id": 4,
                "type": "text",
                "bbox": [
                    285,
                    1452,
                    1213,
                    1564
                ],
                "angle": 0,
                "content": "objects as a function of the set of unique objects produced for all test set events (\\% N/U o)."
            },
            {
                "block_id": 5,
                "type": "text",
                "bbox": [
                    285,
                    1582,
                    1215,
                    2820
                ],
                "angle": 0,
                "content": "Finally, we perform a human evaluation using workers from Amazon Mechanical Turk (AMT). Workers are asked to identify whether a model generation of ATOMIC commonsense adequately completes a plausible tuple of phrase subject, relation, and phrase object. Following the setup of Sap et al. (2019), we evaluate 100 randomly selected events from the test set. For each event and relation type, 10 candidates are generated using beam search and the full beam is evaluated by five different workers. Overall, \\( n = 5000 \\) ratings are produced per relation (100 events × 5 workers × 10 candidates). The reported Avg in Table 2 is an average of these scores, yielding \\( n = 45000 \\) total ratings for each model. We use Pitman's test (Noreen, 1989) with 100k permutations to test for statistical significance. Because 50 different hypotheses are tested (9 relations + the total), the Holm-Bonferroni method (Holm, 1979) is used to correct significance thresholds. Example events from the development set and their generated phrase objects are available in Table 5."
            },
            {
                "block_id": 6,
                "type": "text",
                "bbox": [
                    285,
                    2911,
                    1215,
                    3195
                ],
                "angle": 0,
                "content": "Baselines We report the performance of our method against the models trained in Sap et al. (2019) that use LSTM sequence-to-sequence models (Sutskever et al., 2014) to encode the input subject and relation and produce an output object."
            },
            {
                "block_id": 7,
                "type": "text",
                "bbox": [
                    1265,
                    1452,
                    2195,
                    2409
                ],
                "angle": 0,
                "content": "Ablations To evaluate how pre-training on a large corpus helps the model learn to produce knowledge, we train a version of \\(\\mathbb{C}\\mathsf{OMET}\\) that is not initialized with pre-trained weights (COMET (- pretrain)). We also evaluate the data efficiency of our method by training models on different proportions of the training data. Finally, because the ultimate goal of our method is to be able to perform high-quality, diverse knowledge base construction, we explore how various decoding schemes affect the quality of candidate knowledge tuples. We present the effect of the following generation strategies: argmax greedy decoding, beam search with beam sizes, \\(b = 2\\), 5, 10, and top-\\(k\\) sampling with \\(k = 5\\), 10. For each decoding method, we conduct the human evaluation on the number of final candidates produced by each method."
            },
            {
                "block_id": 8,
                "type": "title",
                "bbox": [
                    1267,
                    2452,
                    1530,
                    2504
                ],
                "angle": 0,
                "content": "4.2 Results"
            },
            {
                "block_id": 9,
                "type": "text",
                "bbox": [
                    1265,
                    2525,
                    2193,
                    2981
                ],
                "angle": 0,
                "content": "Overall performance The BLEU-2 results in Table 1 indicate that \\(\\mathbb{C}\\mathbb{O}\\mathbb{M}\\mathbb{T}\\) exceeds the performance of all baselines, achieving a \\(51\\%\\) relative improvement over the top performing model of Sap et al. (2019). More interesting, however, is the result of the human evaluation, where \\(\\mathbb{C}\\mathbb{O}\\mathbb{M}\\mathbb{T}\\) reported a statistically significant relative Avg performance increase of \\(18\\%\\) over the top baseline,"
            },
            {
                "block_id": 10,
                "type": "page_footnote",
                "bbox": [
                    1265,
                    3009,
                    2193,
                    3101
                ],
                "angle": 0,
                "content": "Sap et al. (2019)'s models were trained with a different vocabulary so a direct perplexity comparison is not possible."
            },
            {
                "block_id": 11,
                "type": "page_footnote",
                "bbox": [
                    1265,
                    3101,
                    2193,
                    3188
                ],
                "angle": 0,
                "content": "6 All test set \\( s \\) do not appear in the training set so all full tuples must be novel."
            },
            {
                "block_id": 12,
                "type": "list",
                "bbox": [
                    1265,
                    3009,
                    2193,
                    3188
                ],
                "angle": 0,
                "content": null
            },
            {
                "block_id": 13,
                "type": "page_number",
                "bbox": [
                    1193,
                    3230,
                    1295,
                    3279
                ],
                "angle": 0,
                "content": "4766"
            }
        ]
    },
    {
        "page_id": 5,
        "ocr_results": [
            {
                "block_id": 0,
                "type": "table",
                "bbox": [
                    297,
                    294,
                    2200,
                    670
                ],
                "angle": 0,
                "content": "<table><tr><td>COMET Decoding method</td><td>oEffect</td><td>oReact</td><td>oWant</td><td>xAttr</td><td>xEffect</td><td>xIntent</td><td>xNeed</td><td>xReact</td><td>xWant</td><td>Avg</td></tr><tr><td>Top-5 random sampling (n=2500 per relation)</td><td>34.60</td><td>44.04</td><td>35.56</td><td>64.56</td><td>55.68</td><td>58.84</td><td>46.68</td><td>80.96</td><td>58.52</td><td>53.27</td></tr><tr><td>Top-10 random sampling (n=5000 per relation)</td><td>25.20</td><td>37.42</td><td>27.34</td><td>49.20</td><td>47.34</td><td>47.06</td><td>38.24</td><td>72.60</td><td>48.10</td><td>43.61</td></tr><tr><td>Beam search - 2 beams (n=1000 per relation)</td><td>43.70</td><td>54.20</td><td>47.60</td><td>84.00</td><td>51.10</td><td>73.80</td><td>50.70</td><td>85.80</td><td>78.70</td><td>63.29</td></tr><tr><td>Beam search - 5 beams (n=2500 per relation)</td><td>37.12</td><td>45.36</td><td>42.04</td><td>63.64</td><td>61.76</td><td>63.60</td><td>57.60</td><td>78.64</td><td>68.40</td><td>57.57</td></tr><tr><td>Beam search - 10 beams (n=5000 per relation)</td><td>29.02</td><td>37.68</td><td>44.48</td><td>57.48</td><td>55.50</td><td>68.32</td><td>64.24</td><td>76.18</td><td>75.16</td><td>56.45</td></tr><tr><td>Greedy decoding (n=500 per relation)</td><td>61.20</td><td>69.80</td><td>80.00</td><td>77.00</td><td>53.00</td><td>89.60</td><td>85.60</td><td>92.20</td><td>89.40</td><td>77.53</td></tr><tr><td>Human validation of gold ATOMIC</td><td>84.62</td><td>86.13</td><td>83.12</td><td>78.44</td><td>83.92</td><td>91.37</td><td>81.98</td><td>95.18</td><td>90.90</td><td>86.18</td></tr></table>",
                "caption": "Table 3: Human evaluation testing effect of different decoding schemes on candidate tuple quality. The number of ratings made per relation for each decoding method is provided in the first column."
            },
            {
                "block_id": 2,
                "type": "table",
                "bbox": [
                    292,
                    880,
                    1213,
                    1241
                ],
                "angle": 0,
                "content": "<table><tr><td>% train data</td><td>PPL</td><td>BLEU-2</td><td>N/T o</td><td>N/U o</td></tr><tr><td>1% train</td><td>23.81</td><td>5.08</td><td>7.24</td><td>49.36</td></tr><tr><td>10% train</td><td>13.74</td><td>12.72</td><td>9.54</td><td>58.34</td></tr><tr><td>50% train</td><td>11.82</td><td>13.97</td><td>9.32</td><td>50.37</td></tr><tr><td>FULL (- pretrain)</td><td>15.18</td><td>13.22</td><td>7.14</td><td>44.55</td></tr><tr><td>FULL train</td><td>11.13</td><td>14.34</td><td>9.51</td><td>50.05</td></tr></table>",
                "caption": "Table 4: Effect of amount of training data on automatic evaluation of commonsense generations"
            },
            {
                "block_id": 4,
                "type": "text",
                "bbox": [
                    285,
                    1494,
                    1215,
                    1831
                ],
                "angle": 0,
                "content": "Event2IN(VOLUN). This performance increase is consistent, as well, with an improvement being observed across every relation type. In addition to the quality improvements, Table 1 shows that COMET produces more novel tuple objects than the baselines, as well."
            },
            {
                "block_id": 5,
                "type": "text",
                "bbox": [
                    285,
                    1918,
                    1215,
                    2539
                ],
                "angle": 0,
                "content": "Learning knowledge from language Significant differences were also observed between the performance of the model whose weights were initialized with the pre-trained parameters from the GPT model of Radford et al. (2018) and a model with the same architecture that was trained from random initialization. This \\(14\\%\\) relative improvement in overall human performance confirms that the language representations learned by the GPT model are transferable to generating natural language commonsense knowledge."
            },
            {
                "block_id": 6,
                "type": "text",
                "bbox": [
                    285,
                    2627,
                    1215,
                    3192
                ],
                "angle": 0,
                "content": "Effect of decoding algorithm In Table 3, we show the effect of different generation policies on knowledge quality. The most interesting result is that using greedy decoding to produce knowledge tuples only results in a \\(10\\%\\) relative performance gap compared to a human evaluation of the ATOMIC test set, showing that the knowledge produced by the model approaches human performance. While producing more total candidates does lower overall performance, quality assess-"
            },
            {
                "block_id": 7,
                "type": "table",
                "bbox": [
                    1280,
                    884,
                    2190,
                    1806
                ],
                "angle": 0,
                "content": "<table><tr><td>Seed Concept</td><td>Relation</td><td>Generated</td><td>Plausible</td></tr><tr><td>X holds out X&#x27;s hand to Y</td><td>xAttr</td><td>helpful</td><td>✓</td></tr><tr><td>X meets Y eyes</td><td>xAttr</td><td>intense</td><td>✓</td></tr><tr><td>X watches Y every _</td><td>xAttr</td><td>observant</td><td>✓</td></tr><tr><td>X eats red meat</td><td>xEffect</td><td>gets fat</td><td>✓</td></tr><tr><td>X makes crafts</td><td>xEffect</td><td>gets dirty</td><td>✓</td></tr><tr><td>X turns X&#x27;s phone</td><td>xEffect</td><td>gets a text</td><td></td></tr><tr><td>X pours _ over Y&#x27;s head</td><td>oEffect</td><td>gets hurt</td><td>✓</td></tr><tr><td>X takes Y&#x27;s head off</td><td>oEffect</td><td>bleeds</td><td>✓</td></tr><tr><td>X pisses on Y&#x27;s bonfire</td><td>oEffect</td><td>gets burned</td><td></td></tr><tr><td>X spoils somebody rotten</td><td>xIntent</td><td>to be mean</td><td></td></tr><tr><td>X gives Y some pills</td><td>xIntent</td><td>to help</td><td>✓</td></tr><tr><td>X provides for Y&#x27;s needs</td><td>xIntent</td><td>to be helpful</td><td>✓</td></tr><tr><td>X explains Y&#x27;s reasons</td><td>xNeed</td><td>to know Y</td><td>✓</td></tr><tr><td>X fulfils X&#x27;s needs</td><td>xNeed</td><td>to have a plan</td><td>✓</td></tr><tr><td>X gives Y everything</td><td>xNeed</td><td>to buy something</td><td>✓</td></tr><tr><td>X eats pancakes</td><td>xReact</td><td>satisfied</td><td>✓</td></tr><tr><td>X makes _ at work</td><td>xReact</td><td>proud</td><td>✓</td></tr><tr><td>X moves house</td><td>xReact</td><td>happy</td><td>✓</td></tr><tr><td>X gives birth to the Y</td><td>oReact</td><td>happy</td><td>✓</td></tr><tr><td>X gives Y&#x27;s friend _</td><td>oReact</td><td>grateful</td><td>✓</td></tr><tr><td>X goes _ with friends</td><td>oReact</td><td>happy</td><td>✓</td></tr><tr><td>X gets all the supplies</td><td>xWant</td><td>to make a list</td><td>✓</td></tr><tr><td>X murders Y&#x27;s wife</td><td>xWant</td><td>to hide the body</td><td>✓</td></tr><tr><td>X starts shopping</td><td>xWant</td><td>to go home</td><td>✓</td></tr><tr><td>X develops Y theory</td><td>oWant</td><td>to thank X</td><td>✓</td></tr><tr><td>X offer Y a position</td><td>oWant</td><td>to accept the job</td><td>✓</td></tr><tr><td>X takes _ out for dinner</td><td>oWant</td><td>to eat</td><td>✓</td></tr></table>",
                "caption": "Table 5: Generations that were randomly selected from a subset of novel generations from the ATOMIC development set. A novel generation is a sro tuple not found in the training set. Manual evaluation of each tuple indicates whether the tuple is considered plausible by a human annotator."
            },
            {
                "block_id": 9,
                "type": "text",
                "bbox": [
                    1265,
                    2231,
                    2193,
                    2459
                ],
                "angle": 0,
                "content": "ments still hover around \\(55\\%^{7}\\) for a beam size of 10. This result suggests that \\(\\complement\\)MET could be effective with human evaluators in the loop to confirm the correctness of generated tuples."
            },
            {
                "block_id": 10,
                "type": "text",
                "bbox": [
                    1265,
                    2490,
                    2193,
                    2943
                ],
                "angle": 0,
                "content": "Efficiency of learning from seed tuples Because not all domains will have large available commonsense KBs on which to train, we explore how varying the amount of training data available for learning affects the quality and novelty of the knowledge that is produced. Our results in Table 4 indicate that even with only \\(10\\%\\) of the available training data, the model is still able to"
            },
            {
                "block_id": 11,
                "type": "page_footnote",
                "bbox": [
                    1265,
                    2974,
                    2193,
                    3192
                ],
                "angle": 0,
                "content": "This number is partially low due to the many \"none\" references in the oEffect, oReact, oWant categories. In any set of 10 candidates, \"none\" can only be predicted once, which causes most candidates in the beam to be incorrect if \"none\" is the appropriate answer."
            },
            {
                "block_id": 12,
                "type": "page_number",
                "bbox": [
                    1193,
                    3230,
                    1292,
                    3279
                ],
                "angle": 0,
                "content": "4767"
            }
        ]
    },
    {
        "page_id": 6,
        "ocr_results": [
            {
                "block_id": 0,
                "type": "text",
                "bbox": [
                    285,
                    266,
                    1215,
                    771
                ],
                "angle": 0,
                "content": "produce generations that are coherent, adequate, and novel. Using only \\(1\\%\\) of the training data clearly diminishes the quality of the produced generations, with significantly lower observed results across both quality and novelty metrics. Interestingly, we note that training the model without pretrained weights performs comparably to training with \\(10\\%\\) of the seed tuples, quantifying the impact of using pre-trained language representations."
            },
            {
                "block_id": 1,
                "type": "title",
                "bbox": [
                    287,
                    820,
                    910,
                    877
                ],
                "angle": 0,
                "content": "5 ConceptNet Experiments"
            },
            {
                "block_id": 2,
                "type": "text",
                "bbox": [
                    285,
                    912,
                    1215,
                    1536
                ],
                "angle": 0,
                "content": "The ConceptNet dataset<sup>8</sup>, provided by Li et al. (2016), consists of tuples obtained from the Open Mind Common Sense (OMCS) entries in ConceptNet 5 (Speer et al., 2017). Tuples are in the standard sro form – (e.g., take a nap, Causes, have energy). The most confident 1200 tuples were used to create the test set, while the next 1200 tuples were used to create two development sets, which we combine in this work. The 100k version of the training set was used to train models, which contains 34 relation types."
            },
            {
                "block_id": 3,
                "type": "title",
                "bbox": [
                    287,
                    1578,
                    521,
                    1634
                ],
                "angle": 0,
                "content": "5.1 Setup"
            },
            {
                "block_id": 4,
                "type": "text",
                "bbox": [
                    285,
                    1655,
                    1215,
                    2613
                ],
                "angle": 0,
                "content": "Metrics We evaluate our models that generate ConceptNet relations using the following metrics. First, we report the perplexity of the gold relations in the test set (PPL). To evaluate the quality of generated knowledge, we also report the number of generated positive examples in the test set that are scored as correct by the pre-trained Bilinear AVG model developed by Li et al. (2016). For a given sro tuple, this model produces a probability for whether the tuple is correct. We threshold scores at \\(50\\%\\) probability to identify positive predictions. On the completion task originally proposed in Li et al. (2016), this model achieved \\(92.5\\%\\) accuracy on the test set, indicating that it is a strong proxy for automatically evaluating whether a generated tuple is correct. Finally, we report the same novelty metrics as for ATOMIC: N/T sro and N/T o."
            },
            {
                "block_id": 5,
                "type": "text",
                "bbox": [
                    285,
                    2652,
                    1215,
                    2936
                ],
                "angle": 0,
                "content": "Baselines As a baseline, we re-implement the BiLSTM model proposed by Saito et al. (2018) with minor modifications outlined in Appendix A.2. This model is trained to learn to encode knowledge in both directions: \\( sr \\rightarrow o \\) and"
            },
            {
                "block_id": 6,
                "type": "table",
                "bbox": [
                    1280,
                    256,
                    2190,
                    547
                ],
                "angle": 0,
                "content": "<table><tr><td>Model</td><td>PPL</td><td>Score</td><td>N/T sRO</td><td>N/T o</td><td>Human</td></tr><tr><td>LSTM - s</td><td>-</td><td>60.83</td><td>86.25</td><td>7.83</td><td>63.86</td></tr><tr><td>CKBG (Saito et al., 2018)</td><td>-</td><td>57.17</td><td>86.25</td><td>8.67</td><td>53.95</td></tr><tr><td>COMET (- pretrain)</td><td>8.05</td><td>89.25</td><td>36.17</td><td>6.00</td><td>83.49</td></tr><tr><td>COMET - RELTOK</td><td>4.39</td><td>95.17</td><td>56.42</td><td>2.62</td><td>92.11</td></tr><tr><td>COMET</td><td>4.32</td><td>95.25</td><td>59.25</td><td>3.75</td><td>91.69</td></tr></table>",
                "caption": "Table 6: ConceptNet generation Results"
            },
            {
                "block_id": 8,
                "type": "text",
                "bbox": [
                    1262,
                    712,
                    2195,
                    992
                ],
                "angle": 0,
                "content": "or \\(\\rightarrow s\\) to help augment a knowledge base completion model. It is only evaluated on the \\( sr \\rightarrow o \\) tuple generation task, however. For posterity, we also include the result from a LSTM model that is only trained on the \\( sr \\rightarrow o \\) task (LSTM - \\( s \\))."
            },
            {
                "block_id": 9,
                "type": "text",
                "bbox": [
                    1262,
                    1020,
                    2195,
                    1866
                ],
                "angle": 0,
                "content": "Ablations We include the following ablations of our full model. First, we evaluate how pretraining on a large-scale corpus (Radford et al., 2018) helps performance by training a comparison model from scratch, denoted \\(\\mathbb{C}\\mathsf{OMET}\\) (- pretrain) in Table 6. Second, in our main model, we map relation names to natural language (e.g., \\(\\mathsf{IsA} \\rightarrow\\) \"is a\"; HasSubevent \\(\\rightarrow\\) \"has subevent\") so the model can learn to represent these concepts with language, as opposed to learning a special embedding from scratch for each relation (Levy et al., 2017). As an ablation, we train a model without converting relation tokens to natural language (e.g., \\(\\mathsf{IsA} \\nRightarrow\\) \"is a\"), which we denote \\(\\mathbb{C}\\mathsf{OMET}-\\mathsf{RELTOK}\\)."
            },
            {
                "block_id": 10,
                "type": "title",
                "bbox": [
                    1267,
                    1904,
                    1528,
                    1953
                ],
                "angle": 0,
                "content": "5.2 Results"
            },
            {
                "block_id": 11,
                "type": "text",
                "bbox": [
                    1262,
                    1978,
                    2193,
                    2711
                ],
                "angle": 0,
                "content": "Quality Our results indicate that high-quality knowledge can be generated by the model: the low perplexity scores in Table 6 indicate high model confidence in its predictions, while the high classifier score (95.25%) indicates that the KB completion model of Li et al. (2016) scores the generated tuples as correct in most of the cases. While adversarial generations could be responsible for this high score, a human evaluation (following the same design as for ATOMIC) scores 91.7% of greedily decoded tuples as correct. Randomly selected examples provided in Table 7 also point to the quality of knowledge produced by the model."
            },
            {
                "block_id": 12,
                "type": "text",
                "bbox": [
                    1262,
                    2739,
                    2195,
                    3192
                ],
                "angle": 0,
                "content": "Novelty In addition to being high quality, the generated tuples from \\(\\mathbb{C}\\mathbb{O}\\mathbb{M}\\mathbb{T}\\) are also novel, with \\(59.25\\%\\) of the tuples not being present in the training set, showing that the model is capable of generating new edges between nodes, and even creating new nodes - \\(3.75\\%\\) of \\(o\\) nodes are novel - to extend the size of the knowledge graph. One shortcoming, however, is that novel generations"
            },
            {
                "block_id": 13,
                "type": "page_footnote",
                "bbox": [
                    287,
                    2967,
                    1153,
                    3055
                ],
                "angle": 0,
                "content": "<https://ttic.uchicago.edu/~kgimpel/commonsense.html>"
            },
            {
                "block_id": 14,
                "type": "page_footnote",
                "bbox": [
                    287,
                    3055,
                    1205,
                    3188
                ],
                "angle": 0,
                "content": "9 A pre-trained model can be found at https://ttic.uchicago.edu/~kgimpel/comsense-resources/ckbc-demo.tar.gz"
            },
            {
                "block_id": 15,
                "type": "list",
                "bbox": [
                    287,
                    2967,
                    1205,
                    3188
                ],
                "angle": 0,
                "content": null
            },
            {
                "block_id": 16,
                "type": "page_number",
                "bbox": [
                    1193,
                    3230,
                    1292,
                    3279
                ],
                "angle": 0,
                "content": "4768"
            }
        ]
    },
    {
        "page_id": 7,
        "ocr_results": [
            {
                "block_id": 0,
                "type": "image",
                "bbox": [
                    315,
                    277,
                    1193,
                    799
                ],
                "angle": 0,
                "content": null,
                "caption": "Figure 4: The percentage of novel ConceptNet development set tuples per minimum edit distance from training tuples. In green: classifier-scored accuracy of each subset."
            },
            {
                "block_id": 2,
                "type": "text",
                "bbox": [
                    285,
                    1126,
                    1210,
                    1575
                ],
                "angle": 0,
                "content": "are sometimes simplified forms of tuples from the training set. In Table 7, for example, the tuple “doctor CapableOf save life” is not present in the training set, but “doctor CapableOf save person life” is. Many tuples, however, are completely novel, such as “bird bone HasProperty fragile” and “driftwood AtLocation beach”, which have no related tuples in the training set."
            },
            {
                "block_id": 3,
                "type": "text",
                "bbox": [
                    285,
                    1582,
                    1213,
                    2760
                ],
                "angle": 0,
                "content": "To explore further, we investigate by how much novel tuples from the development set differ from training set phrase objects for the same \\( s \\), \\( r \\) using minimum edit distance of phrase objects. We measure the edit distance of phrase object \\( o_{dev} \\) in the tuple \\( (s, r, o_{dev}) \\) to the \\( o_{trn} \\) from the nearest training tuple \\( (s, r, o_{trn}) \\). Edit distance is measured using word tokens (excluding stop words) and normalized by the maximum number of words in \\( o_{dev} \\) or \\( o_{trn} \\). The maximum edit distance is one (i.e., entirely different word sequences) and the minimum edit distance is zero (i.e., the same sequence excluding stopwords). Figure 4 shows the percentage of novel development set tuples that have an edit distance from the closest training set tuple of at least the value on the x-axis. Over \\( 75\\% \\) of the novel tuples have objects that are a normalized edit distance of \\( > = 0.5 \\) from the training phrase objects, indicating that most of the novel phrase objects have significantly different word sequences from their closest analogues in the training set."
            },
            {
                "block_id": 4,
                "type": "text",
                "bbox": [
                    285,
                    2795,
                    1213,
                    3188
                ],
                "angle": 0,
                "content": "Learning knowledge from language Similarly to ATOMIC, we explore how pre-training COMET on a large language corpus affects its ability to generalize commonsense. This effect is apparent in Table 6, with a clear improvement on automatic and human evaluations by the pretrained COMET over the randomly initialized"
            },
            {
                "block_id": 5,
                "type": "table",
                "bbox": [
                    1282,
                    256,
                    2185,
                    1326
                ],
                "angle": 0,
                "content": "<table><tr><td>Seed</td><td>Relation</td><td>Completion</td><td>Plausible</td></tr><tr><td>piece</td><td>PartOf</td><td>machine</td><td>✓</td></tr><tr><td>bread</td><td>IsA</td><td>food</td><td>✓</td></tr><tr><td>oldsmobile</td><td>IsA</td><td>car</td><td>✓</td></tr><tr><td>happiness</td><td>IsA</td><td>feel</td><td>✓</td></tr><tr><td>math</td><td>IsA</td><td>subject</td><td>✓</td></tr><tr><td>mango</td><td>IsA</td><td>fruit</td><td>✓</td></tr><tr><td>maine</td><td>IsA</td><td>state</td><td>✓</td></tr><tr><td>planet</td><td>AtLocation</td><td>space</td><td>✓</td></tr><tr><td>dust</td><td>AtLocation</td><td>fridge</td><td></td></tr><tr><td>puzzle</td><td>AtLocation</td><td>your mind</td><td></td></tr><tr><td>college</td><td>AtLocation</td><td>town</td><td>✓</td></tr><tr><td>dental chair</td><td>AtLocation</td><td>dentist</td><td>✓</td></tr><tr><td>finger</td><td>AtLocation</td><td>your finger</td><td></td></tr><tr><td>sing</td><td>Causes</td><td>you feel good</td><td>✓</td></tr><tr><td>doctor</td><td>CapableOf</td><td>save life</td><td>✓</td></tr><tr><td>post office</td><td>CapableOf</td><td>receive letter</td><td>✓</td></tr><tr><td>dove</td><td>SymbolOf</td><td>purity</td><td>✓</td></tr><tr><td>sun</td><td>HasProperty</td><td>big</td><td>✓</td></tr><tr><td>bird bone</td><td>HasProperty</td><td>fragile</td><td>✓</td></tr><tr><td>earth</td><td>HasA</td><td>many plant</td><td>✓</td></tr><tr><td>yard</td><td>UsedFor</td><td>play game</td><td>✓</td></tr><tr><td>get pay</td><td>HasPrerequisite</td><td>work</td><td>✓</td></tr><tr><td>print on printer</td><td>HasPrerequisite</td><td>get printer</td><td>✓</td></tr><tr><td>play game</td><td>HasPrerequisite</td><td>have game</td><td>✓</td></tr><tr><td>live</td><td>HasLastSubevent</td><td>die</td><td>✓</td></tr><tr><td>swim</td><td>HasSubevent</td><td>get wet</td><td>✓</td></tr><tr><td>sit down</td><td>MotivatedByGoal</td><td>you be tire</td><td>✓</td></tr><tr><td>all paper</td><td>ReceivesAction</td><td>recycle</td><td>✓</td></tr><tr><td>chair</td><td>MadeOf</td><td>wood</td><td>✓</td></tr><tr><td>earth</td><td>DefinedAs</td><td>planet</td><td>✓</td></tr></table>",
                "caption": "Table 7: Randomly selected and novel generations from the ConceptNet development set. Novel generations are sro tuples not found in the training set. Manual evaluation of each tuple indicates whether the tuple is considered plausible by a human annotator"
            },
            {
                "block_id": 7,
                "type": "text",
                "bbox": [
                    1265,
                    1718,
                    2193,
                    2283
                ],
                "angle": 0,
                "content": "model. Qualitatively, we observe this effect in Table 7 with the generated example tuple \"mango IsA fruit\", which is not present in the training set. The only tuple containing the \"mango\" entity in the training set is \"mango UsedFor salsa\", which is not informative enough. As confirmation, we observe that the output from \\(\\complement\\)omet (- pretrain) is \"mango IsA spice\", which could be a reasonable inference given the information about \"mango\" in the seed set of knowledge."
            },
            {
                "block_id": 8,
                "type": "text",
                "bbox": [
                    1265,
                    2346,
                    2193,
                    3188
                ],
                "angle": 0,
                "content": "Representing relations with language While the automatic metrics point to insignificant differences when comparing models with symbol relations and those with natural language relations (Table 6), examples can provide qualitative insights into the benefits of representing relations as language. While the only non-ornithological reference to a “dove” in the ConceptNet training set is “dove CapableOf fly”, our model learns to generalize to produce the tuple “dove SymbolOf purity”. The model that uses symbol relation embeddings only manages to produce the relation “dove SymbolOf submarine”, which seems to relate “submarine” to a more nautical (and unrelated) word sense of “dove”."
            },
            {
                "block_id": 9,
                "type": "page_number",
                "bbox": [
                    1193,
                    3230,
                    1292,
                    3279
                ],
                "angle": 0,
                "content": "4769"
            }
        ]
    },
    {
        "page_id": 8,
        "ocr_results": [
            {
                "block_id": 0,
                "type": "title",
                "bbox": [
                    290,
                    263,
                    674,
                    312
                ],
                "angle": 0,
                "content": "6 Related Work"
            },
            {
                "block_id": 1,
                "type": "text",
                "bbox": [
                    287,
                    357,
                    1218,
                    1596
                ],
                "angle": 0,
                "content": "Knowledge base construction Previous work has looked at constructing knowledge bases as relational schemas using expert knowledge (Lenat, 1995; Bodenreider, 2004; Miller, 1995), semistructured text extraction (Suchanek et al., 2007; Hoffart et al., 2013; Auer et al., 2007; Bollacker et al., 2008) and unstructured text extraction (Dong et al., 2014; Carlson et al., 2010; Nakashole et al., 2011, 2012; Niu, 2012). In our work, we focus on construction of commonsense knowledge bases which require the use of open-text events rather than a well-defined relational schema structure. Other work in information extraction can also be applied to knowledge base construction with open-text entities (Soderland et al., 2010; Etzioni et al., 2011; Fader et al., 2011; Mausam et al., 2012; Fan et al., 2010; Cui et al., 2018), but these methods typically extract explicitly stated text relations. Conversely, our approach generates new knowledge that is often unstated in text, as commonsense information typically is (Gordon and Van Durme, 2013)."
            },
            {
                "block_id": 2,
                "type": "text",
                "bbox": [
                    285,
                    1634,
                    1215,
                    2760
                ],
                "angle": 0,
                "content": "Commonsense knowledge base completion Existing work on generation of novel commonsense knowledge has also used ConceptNet and ATOMIC as underlying KBs. Specifically, Li et al. (2016) proposed a set of neural network models for scoring tuples in ConceptNet. Our work differs from this approach as their models evaluate full tuples rather than learning to generate the phrases to make new nodes in the knowledge graph. Saito et al. (2018) builds upon this work by proposing a joint model for completion and generation of commonsense tuples. Their work, however, focuses on using tuple generation to augment their KB completion model, rather than to increase coverage in commonsense KB construction. Finally, Sap et al. (2019) use LSTM encoder-decoder models to generate commonsense knowledge about social situations. We use transformers and investigate the effect of using pre-trained language representations (Radford et al., 2018) to initialize them."
            },
            {
                "block_id": 3,
                "type": "text",
                "bbox": [
                    287,
                    2799,
                    1215,
                    3192
                ],
                "angle": 0,
                "content": "Transformers and pre-training Finally, our work builds on previous work on adapting pretrained language models for various sequence labeling, classification, and NLI end tasks (Radford et al., 2018; Peters et al., 2018; Devlin et al., 2018). Our research investigates how pre-trained language models can be used for large-scale com-"
            },
            {
                "block_id": 4,
                "type": "text",
                "bbox": [
                    1265,
                    266,
                    2195,
                    378
                ],
                "angle": 0,
                "content": "monsense KB construction by generating new graph nodes and edges between nodes."
            },
            {
                "block_id": 5,
                "type": "title",
                "bbox": [
                    1267,
                    427,
                    1597,
                    480
                ],
                "angle": 0,
                "content": "7 Conclusion"
            },
            {
                "block_id": 6,
                "type": "text",
                "bbox": [
                    1265,
                    522,
                    2198,
                    1375
                ],
                "angle": 0,
                "content": "We introduce COMmonsense Transformers (COMET) for automatic construction of commonsense knowledge bases. COMET is a framework for adapting the weights of language models to learn to produce novel and diverse commonsense knowledge tuples. Empirical results on two commonsense knowledge bases, ATOMIC and ConceptNet, show that COMET frequently produces novel commonsense knowledge that human evaluators deem to be correct. These positive results point to future work in extending the approach to a variety of other types of knowledge bases, as well as investigating whether COMET can learn to produce OpenIE-style knowledge tuples for arbitrary knowledge seeds."
            },
            {
                "block_id": 7,
                "type": "title",
                "bbox": [
                    1267,
                    1424,
                    1669,
                    1476
                ],
                "angle": 0,
                "content": "Acknowledgments"
            },
            {
                "block_id": 8,
                "type": "text",
                "bbox": [
                    1265,
                    1518,
                    2198,
                    2252
                ],
                "angle": 0,
                "content": "We thank Thomas Wolf, Ari Holtzman, Chandra Bhagavatula, Peter Clark, Rob Dalton, Ronan Le Bras, Rowan Zellers and Scott Yih for helpful discussions over the course of this project, as well as the anonymous reviewers for their insightful comments. This research was supported in part by NSF (IIS-1524371, IIS-1714566, NRI-1525251), DARPA under the CwC program through the ARO (W911NF-15-1-0543), and Samsung Research. This material is based, in part, upon work supported by the National Science Foundation Graduate Research Fellowship Program under Grant No. DGE-1256082."
            },
            {
                "block_id": 9,
                "type": "title",
                "bbox": [
                    1272,
                    2357,
                    1515,
                    2409
                ],
                "angle": 0,
                "content": "References"
            },
            {
                "block_id": 10,
                "type": "ref_text",
                "bbox": [
                    1270,
                    2441,
                    2198,
                    2631
                ],
                "angle": 0,
                "content": "Sören Auer, Christian Bizer, Georgi Kobilarov, Jens Lehmann, Richard Cyganiak, and Zachary G. Ives. 2007. Dbpedia: A nucleus for a web of open data. In ISWC/ASWC."
            },
            {
                "block_id": 11,
                "type": "ref_text",
                "bbox": [
                    1270,
                    2673,
                    2195,
                    2774
                ],
                "angle": 0,
                "content": "Jimmy Ba, Ryan Kiros, and Geoffrey E. Hinton. 2016. Layer normalization. CoRR, abs/1607.06450."
            },
            {
                "block_id": 12,
                "type": "ref_text",
                "bbox": [
                    1270,
                    2813,
                    2195,
                    2957
                ],
                "angle": 0,
                "content": "Olivier Bodenreider. 2004. The unified medical language system (umlts): Integrating biomedical terminology. *Nucleic acids research*, 32:D267-70."
            },
            {
                "block_id": 13,
                "type": "ref_text",
                "bbox": [
                    1270,
                    3002,
                    2195,
                    3192
                ],
                "angle": 0,
                "content": "Piotr Bojanowski, Edouard Grave, Armand Joulin, and Tomas Mikolov. 2017. Enriching word vectors with subword information. Transactions of the Association for Computational Linguistics, 5:135-146."
            },
            {
                "block_id": 14,
                "type": "list",
                "bbox": [
                    1270,
                    2441,
                    2198,
                    3192
                ],
                "angle": 0,
                "content": null
            },
            {
                "block_id": 15,
                "type": "page_number",
                "bbox": [
                    1193,
                    3230,
                    1292,
                    3279
                ],
                "angle": 0,
                "content": "4770"
            }
        ]
    },
    {
        "page_id": 9,
        "ocr_results": [
            {
                "block_id": 0,
                "type": "ref_text",
                "bbox": [
                    295,
                    270,
                    1210,
                    589
                ],
                "angle": 0,
                "content": "Kurt Bollacker, Colin Evans, Praveen Paritosh, Tim Sturge, and Jamie Taylor. 2008. Freebase: A collaboratively created graph database for structuring human knowledge. In Proceedings of the 2008 ACM SIGMOD International Conference on Management of Data, SIGMOD '08, pages 1247-1250, New York, NY, USA. ACM."
            },
            {
                "block_id": 1,
                "type": "ref_text",
                "bbox": [
                    295,
                    624,
                    1210,
                    905
                ],
                "angle": 0,
                "content": "Andrew Carlson, Justin Betteridge, Bryan Kisiel, Burr Settles, Estevam R. Hruschka, Jr., and Tom M. Mitchell. 2010. Toward an architecture for never-ending language learning. In Proceedings of the Twenty-Fourth AAAI Conference on Artificial Intelligence, AAAI'10, pages 1306-1313. AAAI Press."
            },
            {
                "block_id": 2,
                "type": "ref_text",
                "bbox": [
                    295,
                    936,
                    1208,
                    1027
                ],
                "angle": 0,
                "content": "Lei Cui, Furu Wei, and Ming Zhou. 2018. Neural open information extraction. In ACL."
            },
            {
                "block_id": 3,
                "type": "ref_text",
                "bbox": [
                    295,
                    1066,
                    1210,
                    1248
                ],
                "angle": 0,
                "content": "Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2018. Bert: Pre-training of deep bidirectional transformers for language understanding. arXiv preprint arXiv:1810.04805."
            },
            {
                "block_id": 4,
                "type": "ref_text",
                "bbox": [
                    295,
                    1283,
                    1210,
                    1648
                ],
                "angle": 0,
                "content": "Xin Dong, Evgeniy Gabrilovich, Geremy Heitz, Wilko Horn, Ni Lao, Kevin Murphy, Thomas Strohmann, Shaohua Sun, and Wei Zhang. 2014. Knowledge vault: A web-scale approach to probabilistic knowledge fusion. In Proceedings of the 20th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD '14, pages 601-610, New York, NY, USA. ACM."
            },
            {
                "block_id": 5,
                "type": "ref_text",
                "bbox": [
                    295,
                    1687,
                    1210,
                    1827
                ],
                "angle": 0,
                "content": "Oren Etzioni, Anthony Fader, Janara Christensen, Stephen Soderland, and Mausam. 2011. Open information extraction: The second generation. In *IJCAI*."
            },
            {
                "block_id": 6,
                "type": "ref_text",
                "bbox": [
                    295,
                    1859,
                    1210,
                    2129
                ],
                "angle": 0,
                "content": "Anthony Fader, Stephen Soderland, and Oren Etzioni. 2011. Identifying relations for open information extraction. In Proceedings of the conference on empirical methods in natural language processing, pages 1535-1545. Association for Computational Linguistics."
            },
            {
                "block_id": 7,
                "type": "ref_text",
                "bbox": [
                    295,
                    2171,
                    1210,
                    2353
                ],
                "angle": 0,
                "content": "James Fan, David A. Ferrucci, David Gondek, and Aditya Kalyanpur. 2010. Prismatic: Inducing knowledge from a large scale lexicalized relation resource. In *NAACL-HLT* 2010."
            },
            {
                "block_id": 8,
                "type": "ref_text",
                "bbox": [
                    295,
                    2392,
                    1210,
                    2578
                ],
                "angle": 0,
                "content": "Jonathan Gordon and Benjamin Van Durme. 2013. Reporting bias and knowledge acquisition. In Proceedings of the 2013 workshop on Automated knowledge base construction, pages 25-30. ACM."
            },
            {
                "block_id": 9,
                "type": "ref_text",
                "bbox": [
                    295,
                    2609,
                    1210,
                    2746
                ],
                "angle": 0,
                "content": "Dan Hendrycks and Kevin Gimpel. 2016. Bridging nonlinearities and stochastic regularizers with gaussian error linear units. CoRR, abs/1606.08415."
            },
            {
                "block_id": 10,
                "type": "ref_text",
                "bbox": [
                    295,
                    2781,
                    1210,
                    2880
                ],
                "angle": 0,
                "content": "Sepp Hochreiter and Jürgen Schmidhuber. 1997. Long short-term memory. *Neural Computation*, 9(8)."
            },
            {
                "block_id": 11,
                "type": "ref_text",
                "bbox": [
                    295,
                    2911,
                    1210,
                    3185
                ],
                "angle": 0,
                "content": "Johannes Hoffart, Fabian M. Suchanek, Klaus Berberich, and Gerhard Weikum. 2013. Yago2: A spatially and temporally enhanced knowledge base from wikipedia. Artificial Intelligence, 194:28 - 61. Artificial Intelligence, Wikipedia and Semi-Structured Resources."
            },
            {
                "block_id": 12,
                "type": "list",
                "bbox": [
                    295,
                    270,
                    1210,
                    3185
                ],
                "angle": 0,
                "content": null
            },
            {
                "block_id": 13,
                "type": "ref_text",
                "bbox": [
                    1272,
                    270,
                    2193,
                    406
                ],
                "angle": 0,
                "content": "Sture Holm. 1979. A simple sequentially rejective multiple test procedure. Scandinavian Journal of Statistics, 6(2):65-70."
            },
            {
                "block_id": 14,
                "type": "ref_text",
                "bbox": [
                    1272,
                    445,
                    2190,
                    582
                ],
                "angle": 0,
                "content": "Douglas B Lenat. 1995. Cyc: A large-scale investment in knowledge infrastructure. Communications of the ACM, 38(11):33-38."
            },
            {
                "block_id": 15,
                "type": "ref_text",
                "bbox": [
                    1272,
                    617,
                    2190,
                    757
                ],
                "angle": 0,
                "content": "Omer Levy, Minjoon Seo, Eunsol Choi, and Luke S. Zettlemoyer. 2017. Zero-shot relation extraction via reading comprehension. In CoNLL."
            },
            {
                "block_id": 16,
                "type": "ref_text",
                "bbox": [
                    1272,
                    796,
                    2190,
                    936
                ],
                "angle": 0,
                "content": "Xiang Li, Aynaz Taheri, Lifu Tu, and Kevin Gimpel. 2016. Commonsense knowledge base completion. In ACL, volume 1, pages 1445-1455."
            },
            {
                "block_id": 17,
                "type": "ref_text",
                "bbox": [
                    1272,
                    971,
                    2190,
                    1108
                ],
                "angle": 0,
                "content": "Mausam, Michael Schmitz, Stephen Soderland, Robert Bart, and Oren Etzioni. 2012. Open language learning for information extraction. In EMNLP-CoNLL."
            },
            {
                "block_id": 18,
                "type": "ref_text",
                "bbox": [
                    1272,
                    1143,
                    2190,
                    1238
                ],
                "angle": 0,
                "content": "George A. Miller. 1995. Wordnet: A lexical database for english. Commun. ACM, 38(11):39-41."
            },
            {
                "block_id": 19,
                "type": "ref_text",
                "bbox": [
                    1272,
                    1273,
                    2193,
                    1550
                ],
                "angle": 0,
                "content": "Ndapandula Nakashole, Martin Theobald, and Gerhard Weikum. 2011. Scalable knowledge harvesting with high precision and high recall. In Proceedings of the Fourth ACM International Conference on Web Search and Data Mining, WSDM '11, pages 227-236, New York, NY, USA. ACM."
            },
            {
                "block_id": 20,
                "type": "ref_text",
                "bbox": [
                    1272,
                    1585,
                    2193,
                    1908
                ],
                "angle": 0,
                "content": "Ndapandula Nakashole, Gerhard Weikum, and Fabian Suchanek. 2012. Patty: A taxonomy of relational patterns with semantic types. In Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning, pages 1135-1145. Association for Computational Linguistics."
            },
            {
                "block_id": 21,
                "type": "ref_text",
                "bbox": [
                    1272,
                    1943,
                    2190,
                    2080
                ],
                "angle": 0,
                "content": "Feng Niu. 2012. Web-scale Knowledge-base Construction via Statistical Inference and Learning. Ph.D. thesis, Madison, WI, USA. AAI3524067."
            },
            {
                "block_id": 22,
                "type": "ref_text",
                "bbox": [
                    1272,
                    2118,
                    2190,
                    2213
                ],
                "angle": 0,
                "content": "Eric W Noreen. 1989. Computer intensive methods for hypothesis testing: An introduction. Wiley, NY."
            },
            {
                "block_id": 23,
                "type": "ref_text",
                "bbox": [
                    1272,
                    2248,
                    2190,
                    2388
                ],
                "angle": 0,
                "content": "Jeffrey Pennington, Richard Socher, and Christopher D. Manning. 2014. Glove: Global vectors for word representation. In EMNLP."
            },
            {
                "block_id": 24,
                "type": "ref_text",
                "bbox": [
                    1272,
                    2424,
                    2190,
                    2609
                ],
                "angle": 0,
                "content": "Matthew E. Peters, Mark Neumann, Mohit Iyyer, Matthew Gardner, Christopher Clark, Kenton Lee, and Luke S. Zettlemoyer. 2018. Deep contextualized word representations. CoRR, abs/1802.05365."
            },
            {
                "block_id": 25,
                "type": "ref_text",
                "bbox": [
                    1272,
                    2645,
                    2190,
                    2925
                ],
                "angle": 0,
                "content": "Alec Radford, Karthik Narasimhan, Tim Salimans, and Ilya Sutskever. 2018. Improving language understanding by generative pre-training. URL https://s3-us-west-2. amazonaws.com/openai-assetss/researchcovers/languageunsupervised/language understanding paper.pdf."
            },
            {
                "block_id": 26,
                "type": "ref_text",
                "bbox": [
                    1272,
                    2960,
                    2190,
                    3188
                ],
                "angle": 0,
                "content": "Itsumi Saito, Kyosuke Nishida, Hisako Asano, and Junji Tomita. 2018. Commonsense knowledge base completion and generation. In Proceedings of the 22nd Conference on Computational Natural Language Learning, pages 141-150."
            },
            {
                "block_id": 27,
                "type": "list",
                "bbox": [
                    1272,
                    270,
                    2193,
                    3188
                ],
                "angle": 0,
                "content": null
            },
            {
                "block_id": 28,
                "type": "page_number",
                "bbox": [
                    1193,
                    3234,
                    1287,
                    3276
                ],
                "angle": 0,
                "content": "4771"
            }
        ]
    },
    {
        "page_id": 10,
        "ocr_results": [
            {
                "block_id": 0,
                "type": "ref_text",
                "bbox": [
                    292,
                    270,
                    1210,
                    501
                ],
                "angle": 0,
                "content": "Maarten Sap, Ronan LeBras, Emily Allaway, Chandra Bhagavatula, Nicholas Lourie, Hannah Rashkin, Brendan Roof, Noah A Smith, and Yejin Choi. 2019. Atomic: An atlas of machine commonsense for if-then reasoning. In AAAI."
            },
            {
                "block_id": 1,
                "type": "ref_text",
                "bbox": [
                    292,
                    536,
                    1210,
                    719
                ],
                "angle": 0,
                "content": "Stephen Soderland, Brendan Roof, Bo Qin, Shi Xu, Mausam, and Oren Etzioni. 2010. Adapting open information extraction to domain-specific relations. AI Magazine, 31:93-102."
            },
            {
                "block_id": 2,
                "type": "ref_text",
                "bbox": [
                    292,
                    754,
                    1210,
                    940
                ],
                "angle": 0,
                "content": "Robyn Speer, Joshua Chin, and Catherine Havasi. 2017. Conceptnet 5.5: An open multilingual graph of general knowledge. In Thirty-First AAAI Conference on Artificial Intelligence."
            },
            {
                "block_id": 3,
                "type": "ref_text",
                "bbox": [
                    292,
                    975,
                    1210,
                    1203
                ],
                "angle": 0,
                "content": "Fabian M. Suchanek, Gjergji Kasneci, and Gerhard Weikum. 2007. Yago: A core of semantic knowledge. In Proceedings of the 16th International Conference on World Wide Web, WWW '07, pages 697-706, New York, NY, USA. ACM."
            },
            {
                "block_id": 4,
                "type": "ref_text",
                "bbox": [
                    292,
                    1238,
                    1210,
                    1424
                ],
                "angle": 0,
                "content": "Ilya Sutskever, Oriol Vinyals, and Quoc V Le. 2014. Sequence to sequence learning with neural networks. In Advances in Neural Information Processing Systems."
            },
            {
                "block_id": 5,
                "type": "ref_text",
                "bbox": [
                    292,
                    1459,
                    1210,
                    1645
                ],
                "angle": 0,
                "content": "Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, and Illia Polosukhin. 2017. Attention is all you need. In NIPS."
            },
            {
                "block_id": 6,
                "type": "list",
                "bbox": [
                    292,
                    270,
                    1210,
                    1645
                ],
                "angle": 0,
                "content": null
            },
            {
                "block_id": 7,
                "type": "page_number",
                "bbox": [
                    1193,
                    3234,
                    1292,
                    3276
                ],
                "angle": 0,
                "content": "4772"
            }
        ]
    },
    {
        "page_id": 11,
        "ocr_results": [
            {
                "block_id": 0,
                "type": "title",
                "bbox": [
                    287,
                    263,
                    975,
                    319
                ],
                "angle": 0,
                "content": "A Additional Training Details"
            },
            {
                "block_id": 1,
                "type": "title",
                "bbox": [
                    287,
                    354,
                    942,
                    410
                ],
                "angle": 0,
                "content": "A.1 Training Hyperparameters"
            },
            {
                "block_id": 2,
                "type": "text",
                "bbox": [
                    285,
                    427,
                    1215,
                    1101
                ],
                "angle": 0,
                "content": "ATOMIC For ATOMIC, we use a maximum learning rate of 6.25e-5 with a warmup period of 100 minibatches. After, we decay the learning rate linearly until the end of training. We train for 50k minibatches and use early stopping. We clip gradients when their norm is greater than 1. The remainder of our hyperparameters are the same as in Radford et al. (2018). We use the public HuggingFace implementation of the GPT model as a base for our experiments available at: https://github.com/huggingface/pytorch-openai-transformer-lm."
            },
            {
                "block_id": 3,
                "type": "text",
                "bbox": [
                    285,
                    1140,
                    1215,
                    1480
                ],
                "angle": 0,
                "content": "ConceptNet For ConceptNet, we use a maximum learning rate of 1e-5 and a warm-up period of 200 minibatches. The learning rate is decayed linearly until the end of training, which lasts for 100k minibatches. All other hyperparameters are the same as for training on the ATOMIC corpus."
            },
            {
                "block_id": 4,
                "type": "title",
                "bbox": [
                    287,
                    1518,
                    816,
                    1575
                ],
                "angle": 0,
                "content": "A.2 ConceptNet baseline"
            },
            {
                "block_id": 5,
                "type": "text",
                "bbox": [
                    285,
                    1592,
                    1215,
                    2557
                ],
                "angle": 0,
                "content": "We train the ConceptNet baseline with a learning rate of 1e-4 for 100k minibatches. Early stopping is used with the validation loss. Similarly to Saito et al. (2018), we use 200-dimension hidden states and 200-dimensional word embeddings. We use a single-layer bidirectional LSTM (Hochreiter and Schmidhuber, 1997) to encode the first phrase and a single-layer unidirectional LSTM to decode the target phrase. Relation embeddings are concatenated with the word embeddings of the decoder before being input to the decoder LSTM. We set the dropout rate to 0.2 before the output projection layer and after the word embedding layers. We outline the following differences between our reimplementation of the model of Saito et al. (2018) and their original implementation and the reason for the change."
            },
            {
                "block_id": 6,
                "type": "text",
                "bbox": [
                    327,
                    2599,
                    1215,
                    3108
                ],
                "angle": 0,
                "content": "1. We use Glove (Pennington et al., 2014) embeddings rather than fastText embeddings (Bojanowski et al., 2017) to initialize word embeddings. Because the model indicated that 200-dimensional word embeddings were used, we could not use the pretrained embeddings provided by the fastText group<sup>1</sup>. In Saito et al. (2018), the authors described training their fastText embeddings on"
            },
            {
                "block_id": 7,
                "type": "text",
                "bbox": [
                    1354,
                    263,
                    2195,
                    487
                ],
                "angle": 0,
                "content": "Wikipedia. With no reference to the precise corpus used, we opted to use Glove embeddings to initialize the word embeddings of the encoder and decoder instead."
            },
            {
                "block_id": 8,
                "type": "text",
                "bbox": [
                    1305,
                    526,
                    2195,
                    971
                ],
                "angle": 0,
                "content": "2. We use the Adam optimizer with learning rate of 0.0001, rather than SGD with a learning rate of 1.0 because after training both models, we found that the Adam-trained model performed better on development set perplexity. We also do not use weight decay, as this seemed to lower validation performance, as well."
            },
            {
                "block_id": 9,
                "type": "text",
                "bbox": [
                    1305,
                    1013,
                    2195,
                    1354
                ],
                "angle": 0,
                "content": "3. We do not train the generation model jointly with the completion model. We only train an individual generator. The results of Saito et al. (2018) did not show a significant difference in generation performance between the two on the ConceptNet dataset."
            },
            {
                "block_id": 10,
                "type": "text",
                "bbox": [
                    1305,
                    1389,
                    2195,
                    1669
                ],
                "angle": 0,
                "content": "4. We train a second baseline (LSTM - \\(s\\)) that does not learn to produce relations in both directions (i.e., \\(sr \\to o\\) and \\(or \\to s\\)). Instead if only learns parameters that can produce relations in the forward direction (\\(sr \\to o\\))"
            },
            {
                "block_id": 11,
                "type": "text",
                "bbox": [
                    1305,
                    1708,
                    2193,
                    1876
                ],
                "angle": 0,
                "content": "5. We do not decay the learning rate because it was unclear from the original paper what the exact learning rate schedule was."
            },
            {
                "block_id": 12,
                "type": "list",
                "bbox": [
                    1305,
                    526,
                    2195,
                    1876
                ],
                "angle": 0,
                "content": null
            },
            {
                "block_id": 13,
                "type": "title",
                "bbox": [
                    1267,
                    1957,
                    1999,
                    2010
                ],
                "angle": 0,
                "content": "B Additional Evaluation Details"
            },
            {
                "block_id": 14,
                "type": "title",
                "bbox": [
                    1267,
                    2048,
                    1783,
                    2097
                ],
                "angle": 0,
                "content": "B.1 Human Evaluations"
            },
            {
                "block_id": 15,
                "type": "text",
                "bbox": [
                    1262,
                    2118,
                    2193,
                    2683
                ],
                "angle": 0,
                "content": "We used Amazon Mechanical Turk to get ratings of model output accuracy. We selected seed concepts and relations from the test set and generated completions using each model to create \\((s,r,o)\\) tuples. For ATOMIC, we selected tuples by choosing all possible relations (9) for each of 100 randomly selected seed concepts (900 total \\((s,r)\\) pairs) following the procedure from Sap et al. (2019). For ConceptNet, we used the full test set (1200 total \\((s,r)\\) pairs)."
            },
            {
                "block_id": 16,
                "type": "text",
                "bbox": [
                    1262,
                    2687,
                    2195,
                    3076
                ],
                "angle": 0,
                "content": "For Beam-2/5/10 and top-5/10 sampling generations, we used the model to generate 2, 5, or 10 (respectively) possible completions \\((o)\\) per \\((s,r)\\) pair. Workers were shown the full set and asked to select all of the \\(o\\) that are valid completions for the \\((s,r)\\) pair. Each set of tuples was rated by 5 workers."
            },
            {
                "block_id": 17,
                "type": "text",
                "bbox": [
                    1265,
                    3080,
                    2193,
                    3195
                ],
                "angle": 0,
                "content": "For greedy sampling generations, we used the model to generate one possible completion \\((o)\\) per"
            },
            {
                "block_id": 18,
                "type": "page_footnote",
                "bbox": [
                    342,
                    3139,
                    640,
                    3192
                ],
                "angle": 0,
                "content": "\\(^{1}\\)https://fasttext.cc/"
            },
            {
                "block_id": 19,
                "type": "page_number",
                "bbox": [
                    1193,
                    3230,
                    1292,
                    3279
                ],
                "angle": 0,
                "content": "4773"
            }
        ]
    },
    {
        "page_id": 12,
        "ocr_results": [
            {
                "block_id": 0,
                "type": "text",
                "bbox": [
                    287,
                    263,
                    1210,
                    431
                ],
                "angle": 0,
                "content": "\\((s,r)\\) pair. Workers were shown the completed tuple \\((s,r,o)\\) and asked whether it is valid or not. Each tuple was rated by 5 workers."
            },
            {
                "block_id": 1,
                "type": "text",
                "bbox": [
                    287,
                    434,
                    1210,
                    617
                ],
                "angle": 0,
                "content": "We measure accuracy as the percentage of distinct worker responses where the \\((s,r,o)\\) tuple is marked as valid (i.e., \\(\\frac{\\#valid}{5\\cdot|(s,r,o)|}\\))."
            },
            {
                "block_id": 2,
                "type": "title",
                "bbox": [
                    287,
                    652,
                    764,
                    712
                ],
                "angle": 0,
                "content": "C Example Outputs"
            },
            {
                "block_id": 3,
                "type": "text",
                "bbox": [
                    287,
                    743,
                    1210,
                    968
                ],
                "angle": 0,
                "content": "Additional examples can be seen in Figures 5, 6, and 7 that are produced using the demo at https://mosaickg.apps.allenai.org."
            },
            {
                "block_id": 4,
                "type": "title",
                "bbox": [
                    287,
                    1010,
                    1096,
                    1069
                ],
                "angle": 0,
                "content": "D Additional Training Experiments"
            },
            {
                "block_id": 5,
                "type": "text",
                "bbox": [
                    285,
                    1101,
                    1210,
                    1494
                ],
                "angle": 0,
                "content": "In addition to the more naive setups for knowledge graph completion, we explore various multitask and hierarchical learning setups on top of the taxonomy of commonsense relations given by Sap et al. (2019), which group together along various axes (e.g., related to agent/theme, related to causes/effects, etc.)."
            },
            {
                "block_id": 6,
                "type": "title",
                "bbox": [
                    287,
                    1536,
                    868,
                    1589
                ],
                "angle": 0,
                "content": "D.1 Multi-relation Training"
            },
            {
                "block_id": 7,
                "type": "text",
                "bbox": [
                    285,
                    1613,
                    1213,
                    2511
                ],
                "angle": 0,
                "content": "For the ATOMIC corpus, we experiment with multiple multi-task training setups, similar to Sap et al. (2019). First, we train an individual model for each relation type (oReact, oEffect, etc.), which we denote as \\(\\mathbb{C}\\mathbb{O}\\mathbb{M}\\mathbb{E}\\mathbb{T}\\) - 9LM in the Table 9. We also experiment with various information-sharing dataset configurations that organize different relations across common dimensions. We outline these dimensions and the makeup of each split in Table 9. For ConceptNet, all models are always trained on all relation types jointly. Results on automatic evaluation metrics are provided in Table 11. Because there did not seem to be significant differences between these performances and that of \\(\\mathbb{C}\\mathbb{O}\\mathbb{M}\\mathbb{E}\\mathbb{T}\\) - FULL, we did not run additional experiments on these ablations."
            },
            {
                "block_id": 8,
                "type": "title",
                "bbox": [
                    287,
                    2553,
                    962,
                    2606
                ],
                "angle": 0,
                "content": "D.2 Concept Hierarchy Training"
            },
            {
                "block_id": 9,
                "type": "text",
                "bbox": [
                    285,
                    2631,
                    1213,
                    3192
                ],
                "angle": 0,
                "content": "Leveraging the prior knowledge that certain relation types in the ATOMIC knowledge graph are linked to each other, we explore providing these group identities as additional tokens in the relation. For example, when generating the completion of a xReact relation, the model would receive as input the following meta-tokens: <xReact>, <X>, <POST>, <Involuntary> – thereby providing common context with other relations that are part of the same groupings (e.g.,"
            },
            {
                "block_id": 10,
                "type": "text",
                "bbox": [
                    1265,
                    266,
                    2193,
                    1108
                ],
                "angle": 0,
                "content": "generating a phrase for a xWant relation would receive the \\(<\\mathrm{X}>\\) and \\(<\\mathrm{POST}>\\) tokens as input, but not \\(<\\mathrm{Involuntary}>\\)). Depending on the relation for a particular training example (e.g., xReact), a set of meta-tokens are appended to the relation tokens, \\(X^r\\), that provide hierarchical relational information, allowing the model to share information across relation types. We provide a more in-depth description of the category hierarchy training combinations in Table 10. Results on human evaluation metrics are provided in Table 12. Because the model with the hierarchical meta-tokens performed worse than the regular COMET, we did not run additional experiments on this ablations."
            },
            {
                "block_id": 11,
                "type": "page_number",
                "bbox": [
                    1193,
                    3230,
                    1292,
                    3279
                ],
                "angle": 0,
                "content": "4774"
            }
        ]
    },
    {
        "page_id": 13,
        "ocr_results": [
            {
                "block_id": 0,
                "type": "image",
                "bbox": [
                    359,
                    568,
                    2138,
                    2732
                ],
                "angle": 0,
                "content": null,
                "caption": "Figure 5: Example outputs for the event \"PersonX gives PersonY a pep talk\" from \\(\\mathbb{C}\\mathbb{O}\\mathbb{M}\\mathbb{T}\\) trained on the ATOMIC knowledge graph"
            },
            {
                "block_id": 2,
                "type": "page_number",
                "bbox": [
                    1193,
                    3230,
                    1290,
                    3279
                ],
                "angle": 0,
                "content": "4775"
            }
        ]
    },
    {
        "page_id": 14,
        "ocr_results": [
            {
                "block_id": 0,
                "type": "image",
                "bbox": [
                    382,
                    413,
                    2158,
                    2820
                ],
                "angle": 0,
                "content": null,
                "caption": "Figure 6: Example outputs for the event \"Eric wants to see a movie\" from \\(\\mathbb{C}\\mathbb{O}\\mathbb{M}\\mathbb{T}\\) trained on the ATOMIC knowledge graph. \\(\\mathbb{C}\\mathbb{O}\\mathbb{M}\\mathbb{T}\\) is able to generalize beyond the templates of the ATOMIC knowledge graph (i.e., PersonX) and can be used directly with names."
            },
            {
                "block_id": 2,
                "type": "page_number",
                "bbox": [
                    1193,
                    3230,
                    1295,
                    3279
                ],
                "angle": 0,
                "content": "4776"
            }
        ]
    },
    {
        "page_id": 15,
        "ocr_results": [
            {
                "block_id": 0,
                "type": "image",
                "bbox": [
                    399,
                    484,
                    2160,
                    2820
                ],
                "angle": 0,
                "content": null,
                "caption": "Figure 7: Example outputs for the event \"Tom asked Jessica if he could use her car\" from \\(\\complement\\)ET trained on the ATOMIC knowledge graph"
            },
            {
                "block_id": 2,
                "type": "page_number",
                "bbox": [
                    1193,
                    3230,
                    1295,
                    3279
                ],
                "angle": 0,
                "content": "4777"
            }
        ]
    },
    {
        "page_id": 16,
        "ocr_results": [
            {
                "block_id": 0,
                "type": "table",
                "bbox": [
                    439,
                    343,
                    2046,
                    1852
                ],
                "angle": 0,
                "content": "<table><tr><td>Event</td><td>Description</td><td>Example Completion:</td></tr><tr><td></td><td></td><td>Person X puts Person X&#x27;s trust in Person Y</td></tr><tr><td>oEffect</td><td>The effect the event has on others be-sides Person X</td><td>is considered trustworthy is believed gains Person X&#x27;s loyalty</td></tr><tr><td>oReact</td><td>The reaction of others besides Person X to the event</td><td>trusted honored trustworthy</td></tr><tr><td>oWant</td><td>What others besides Person X may want to do after the event</td><td>work with Person X partner with Person X to help Person X</td></tr><tr><td>xAttr</td><td>How Person X might be described given their part in the event</td><td>faithful hopeful trusting</td></tr><tr><td>xEffect</td><td>The effect that the event would have on Person X</td><td>gets relieved stays faithful Is betrayed</td></tr><tr><td>xIntent</td><td>The reason why X would cause the event</td><td>to be trusting his or her help/guidance/advice to be friends</td></tr><tr><td>xNeed</td><td>What Person X might need to do be-fore the event</td><td>to be friends with Person Y to have heard a lot of good things about Per-son Y to get to know Person Y</td></tr><tr><td>xReact</td><td>The reaction that Person X would have to the event</td><td>trusting safe, not alone understood</td></tr><tr><td>xWant</td><td>What Person X may want to do after the event</td><td>to rely on Person Y to go into business with Person Y to make sure that their heart feeling is right</td></tr></table>",
                "caption": "Table 8: Definitions of the relations in ATOMIC. Events in ATOMIC center around the personal situations of a central figure, Person X, with potentially more participants."
            },
            {
                "block_id": 2,
                "type": "table",
                "bbox": [
                    359,
                    2203,
                    2128,
                    2950
                ],
                "angle": 0,
                "content": "<table><tr><td>Organization</td><td>Description</td><td>Relations</td></tr><tr><td>PERSON X/Y</td><td>The training set is split into relations for the subjects of the event (Person X) and relations for other participants in the event</td><td>T1={xAttr, xEffect, xIntent, xNeed, xReact, xWant}T2={oEffect, oReact, oWant}</td></tr><tr><td>PRE/POST</td><td>Event preconditions are jointly trained (i.e., intentions, needs). Event postconditions are jointly trained.</td><td>T1={xIntent, xNeed}T2={oEffect, oReact, oWant, xEffect, xReact, xWant}</td></tr><tr><td>(IN)VOLUN</td><td>Involuntary relations are trained jointly, such as reactions and effects. Voluntary relations are trained jointly, such as needs, wants, and intents.</td><td>T1={oWant, xIntent, xNeed, xWant}T2={oEffect, oReact, xAttr, xEffect, xReact}</td></tr><tr><td>FULL</td><td>The training set is made up of all relations and the model is trained jointly on all of them</td><td>T1={oEffect, oReact, oWant, xAttr, xEffect, xIntent, xNeed, xReact, xWant}</td></tr></table>",
                "caption": "Table 9: Multi-relation training setups. Following Sap et al. (2019), the xAttr relation is not included in the PRE/POST training configuration"
            },
            {
                "block_id": 4,
                "type": "page_number",
                "bbox": [
                    1190,
                    3230,
                    1292,
                    3279
                ],
                "angle": 0,
                "content": "4778"
            }
        ]
    },
    {
        "page_id": 17,
        "ocr_results": [
            {
                "block_id": 0,
                "type": "table",
                "bbox": [
                    359,
                    434,
                    2131,
                    1231
                ],
                "angle": 0,
                "content": "<table><tr><td>Meta-Token</td><td>Description</td><td>Relations</td></tr><tr><td>&lt;X&gt;</td><td>Appended to relations that describe an attribute of Person X</td><td>xAttr, xEffect, xIntent, xNeed, xReact, xWant</td></tr><tr><td>&lt;Y&gt;</td><td>Appended to relations that describes an attribute of a participant that is not Per-son X</td><td>oEffect, oReact, oWant</td></tr><tr><td>&lt;Pre&gt;</td><td>Appended to relations that correspond to pre-conditions of the event</td><td>xIntent, xNeed</td></tr><tr><td>&lt;Post&gt;</td><td>Appended to relations that correspond to post-conditions of the event</td><td>oEffect, oReact, oWant, xEffect, xReact, xWant</td></tr><tr><td>&lt;Voluntary&gt;</td><td>Appended to relations that correspond to voluntary dimensions of the situation</td><td>oWant, xIntent, xNeed, xWant</td></tr><tr><td>&lt;Involuntary&gt;</td><td>Appended to relations that correspond to involuntary dimensions of the situa-tion</td><td>oEffect, oReact, xAttr, xEffect, xReact</td></tr></table>",
                "caption": "Table 10: Category hierarchy meta-tokens, along with the description and the relations to which they are appended"
            },
            {
                "block_id": 2,
                "type": "table",
                "bbox": [
                    491,
                    1701,
                    2007,
                    2167
                ],
                "angle": 0,
                "content": "<table><tr><td>Model</td><td>PPL3</td><td>BLEU-2</td><td>N/T sro4</td><td>N/T o</td><td>N/U o</td></tr><tr><td>COMET-9LM</td><td>11.72</td><td>14.89</td><td>100.00</td><td>9.45</td><td>49.89</td></tr><tr><td>COMET-(IN)VOLUN</td><td>11.38</td><td>14.99</td><td>100.00</td><td>8.60</td><td>48.36</td></tr><tr><td>COMET-PERSONX/Y</td><td>11.30</td><td>15.21</td><td>100.00</td><td>9.12</td><td>49.59</td></tr><tr><td>COMET-PRE/POST</td><td>11.35</td><td>14.88</td><td>100.00</td><td>9.86</td><td>51.86</td></tr><tr><td>COMET-FULL (-pretrain)</td><td>15.42</td><td>13.88</td><td>100.00</td><td>7.25</td><td>45.71</td></tr><tr><td>COMET-FULL</td><td>11.14</td><td>15.10</td><td>100.00</td><td>9.71</td><td>51.20</td></tr><tr><td>COMET-FULL (+ hierarchical meta-tokens)</td><td>10.98</td><td>15.27</td><td>100.00</td><td>10.03</td><td>51.97</td></tr></table>",
                "caption": "Table 11: Automatic evaluations of quality and novelty for generations of ATOMIC commonsense that are trained with the training set split along different relation types. The training splits are outlined in Table 9."
            },
            {
                "block_id": 4,
                "type": "table",
                "bbox": [
                    297,
                    2690,
                    2195,
                    2862
                ],
                "angle": 0,
                "content": "<table><tr><td>Model</td><td>oEffect</td><td>oReact</td><td>oWant</td><td>xAttr</td><td>xEffect</td><td>xIntent</td><td>xNeed</td><td>xReact</td><td>xWant</td><td>Total</td></tr><tr><td>COMET</td><td>29.02</td><td>37.68</td><td>44.48</td><td>57.48</td><td>55.50</td><td>68.32</td><td>64.24</td><td>76.18</td><td>75.16</td><td>56.45</td></tr><tr><td>COMET (+ hierarchy meta-tokens)</td><td>28.46</td><td>38.96</td><td>43.64</td><td>51.90</td><td>50.84</td><td>63.00</td><td>63.98</td><td>66.20</td><td>75.82</td><td>53.64</td></tr></table>",
                "caption": "Table 12: Human score of generations of ATOMIC commonsense for the regular COMET model and the COMET + category meta tokens"
            },
            {
                "block_id": 6,
                "type": "page_number",
                "bbox": [
                    1193,
                    3230,
                    1295,
                    3279
                ],
                "angle": 0,
                "content": "4779"
            }
        ]
    }
]