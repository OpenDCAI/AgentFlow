import os
import json
import argparse
from pathlib import Path
from typing import List, Dict, Any

# ä¾èµ–åº“å¯¼å…¥
try:
    from vllm import LLM
    from PIL import Image
    from pdf2image import convert_from_path # ç”¨äºå°† PDF è½¬æ¢ä¸ºå›¾ç‰‡
    from mineru_vl_utils import MinerUClient
    from mineru_vl_utils import MinerULogitsProcessor # vllm>=0.10.1 æ¨è
except ImportError as e:
    print(f"Error importing required libraries: {e}")
    print("Please ensure you have installed them: pip install 'mineru-vl-utils[vllm]' pdf2image Pillow")
    exit(1)


class MinerUPDFProcessor:
    """
    ä½¿ç”¨ MinerU æ¨¡å‹å’Œ vLLM å¼•æ“æ‰¹é‡å¤„ç† PDF æ–‡ä»¶ï¼Œè¿›è¡Œä¸¤æ­¥æå–å’Œåå¤„ç†ã€‚
    """
    def __init__(self, model_name: str = "/mnt/shared-storage-user/mineru2-shared/zhengyuanhong/MinerU2.5-2509-1.2B/"):
        print("ğŸš€ Initializing vLLM Engine and MinerU Client...")
        
        # 1. åˆå§‹åŒ– vLLM å¼•æ“
        # æ³¨æ„ï¼šæ­¤å¤„å‡è®¾æ‚¨çš„ç¯å¢ƒå¯ä»¥æ”¯æŒæ­¤æ¨¡å‹ï¼ˆæ˜¾å­˜ã€ç¡¬ä»¶ï¼‰
        self.llm = LLM(
            model=model_name,
            # æ·»åŠ  LogitsProcessor ä»¥ä¼˜åŒ– MinerU çš„é‡‡æ ·ï¼Œè¦æ±‚ vllm>=0.10.1
            logits_processors=[MinerULogitsProcessor] 
        )
        
        # 2. åˆå§‹åŒ– MinerU å®¢æˆ·ç«¯
        self.client = MinerUClient(
            backend="vllm-engine",
            vllm_llm=self.llm
        )
        print("âœ… Initialization complete.")

    def _extract_ocr_content_from_page(self, page_image: Image.Image, page_results: List[Dict]) -> List[Dict]:
        """
        å¤„ç† 1: æå– OCR å†…å®¹ï¼Œå¹¶å°†å½’ä¸€åŒ–åæ ‡è½¬æ¢ä¸ºåƒç´ åæ ‡ã€‚
        """
        page_ocr_content = []
        image_width, image_height = page_image.size
        
        for block_index, block in enumerate(page_results):
            # å°†å½’ä¸€åŒ– bbox [x_min, y_min, x_max, y_max] è½¬æ¢ä¸ºåƒç´ å€¼
            bbox = [
                    int(block['bbox'][0] * image_width), 
                    int(block['bbox'][1] * image_height), 
                    int(block['bbox'][2] * image_width), 
                    int(block['bbox'][3] * image_height)
                ]

            page_ocr_content.append({
                "block_id": block_index,
                "type": block.get('type', ''),
                "bbox": bbox,
                "angle": block.get('angle', 0), 
                "content": block.get('content', '')
            })
        return page_ocr_content

    def _match_caption_and_cleanup(self, page_ocr_content: List[Dict]) -> List[Dict]:
        """
        å¤„ç† 2: åŒ¹é…å›¾è¡¨æ ‡é¢˜ï¼ˆcaptionï¼‰å¹¶æ¸…ç†ï¼š
        1. è¯†åˆ«ç±»å‹ä¸­åŒ…å« 'caption' çš„å—ã€‚
        2. å°†å…¶å†…å®¹åˆå¹¶åˆ°ç›¸é‚»çš„ 'table' æˆ– 'image' ç­‰ä¸»å—çš„ 'caption' å­—æ®µä¸­ã€‚
        3. ç§»é™¤åŸå§‹çš„ caption å—ã€‚
        """
        
        indices_to_remove = set()
        
        for i, block in enumerate(page_ocr_content):
            block_type = block.get('type', '')
            
            if "caption" in block_type.lower(): # ä½¿ç”¨ .lower() ç¡®ä¿åŒ¹é…
                # å°è¯•è·å–ä¸»ç±»å‹å (e.g., 'table_caption' -> 'table')
                type_parts = block_type.split('_')
                type_name = type_parts[0] if type_parts and type_parts[-1] == 'caption' else None
                
                caption_content = block.get('content', '')
                
                if not type_name:
                    # å¦‚æœä¸æ˜¯æ ‡å‡†çš„ 'type_caption' æ ¼å¼ï¼Œå°è¯•é€šç”¨åŒ¹é…
                    type_name = None 
                
                matched = False

                # 1. æ£€æŸ¥å‰ä¸€ä¸ªé¡¹ç›®
                if i > 0:
                    prev_block = page_ocr_content[i-1]
                    # åŒ¹é…é€»è¾‘ï¼šå¦‚æœå½“å‰å—æ˜¯ captionï¼Œå‰ä¸€å—æ˜¯å…¶å¯¹åº”çš„ä¸»ä½“å—
                    if type_name is None or prev_block.get('type') == type_name:
                        prev_block['caption'] = caption_content
                        matched = True
                        
                # 2. å¦‚æœå‰ä¸€ä¸ªæ²¡æœ‰åŒ¹é…ä¸Šï¼Œæ£€æŸ¥ä¸‹ä¸€ä¸ªé¡¹ç›®
                if not matched and i < len(page_ocr_content) - 1:
                    next_block = page_ocr_content[i+1]
                    # åŒ¹é…é€»è¾‘ï¼šå¦‚æœå½“å‰å—æ˜¯ captionï¼Œåä¸€å—æ˜¯å…¶å¯¹åº”çš„ä¸»ä½“å—
                    if type_name is None or next_block.get('type') == type_name:
                        next_block['caption'] = caption_content
                        matched = True
                
                # å¦‚æœåŒ¹é…æˆåŠŸï¼Œåˆ™å°†å½“å‰ caption å—æ ‡è®°ä¸ºç§»é™¤
                if matched:
                    indices_to_remove.add(i)
        
        # ç§»é™¤å·²åˆå¹¶çš„ caption å—
        new_page_ocr_content = [
            block for i, block in enumerate(page_ocr_content) if i not in indices_to_remove
        ]
        
        return new_page_ocr_content

    def process_pdf(self, pdf_path: Path, output_dir: Path):
        """
        å¤„ç†å•ä¸ª PDF æ–‡ä»¶ï¼šæ‹†åˆ†é¡µé¢ï¼Œæ‰¹é‡æ¨ç†ï¼Œå¹¶è¿›è¡Œåå¤„ç†ã€‚
        """
        base_name = pdf_path.stem
        print(f"\nğŸ“„ Starting processing for: {pdf_path.name}")
        
        # 1. PDF è½¬æ¢ä¸ºå›¾ç‰‡ï¼ˆpagesæ˜¯ä¸€ä¸ªPIL.Imageåˆ—è¡¨ï¼‰
        pages = convert_from_path(str(pdf_path), dpi=300)

        # 2. **å…³é”®ä¼˜åŒ–ï¼šå°†æ‰€æœ‰é¡µé¢ä½œä¸ºä¸€ä¸ªæ‰¹æ¬¡è¿›è¡Œ vLLM æ¨ç†**
        print(f"   -> Found {len(pages)} pages. Running vLLM inference in batch mode...")
        
        # all_page_results = self.client.two_step_extract(pages)
        all_page_results = self.client.batch_two_step_extract(pages)


        print("   -> Inference complete. Starting post-processing.")
        
        # 3. åå¤„ç†å’Œæ ¼å¼åŒ–
        pdf_results = []
        for i, (page_image, page_results) in enumerate(zip(pages, all_page_results)):
            
            # å¤„ç† 1: æ ¼å¼åŒ–å’Œåæ ‡è½¬æ¢
            page_ocr_content = self._extract_ocr_content_from_page(page_image, page_results)
            
            # å¤„ç† 2: åŒ¹é… caption å’Œæ¸…ç†
            processed_content = self._match_caption_and_cleanup(page_ocr_content)
            
            pdf_results.append({"page_id": i, "ocr_results": processed_content})

        # 4. å­˜å‚¨ç»“æœ
        json_output_file = output_dir / f"{base_name}_ocr.json"
        with open(json_output_file, 'w', encoding='utf-8') as f:
            json.dump(pdf_results, f, ensure_ascii=False, indent=4)
            
        print(f"   -> Successfully processed and saved to: {json_output_file}")


    def run_batch_processing(self, input_dir: Path, output_dir: Path):
        """
        éå†è¾“å…¥ç›®å½•ï¼Œå¤„ç†æ‰€æœ‰ PDF æ–‡ä»¶ã€‚
        """
        if not input_dir.is_dir():
            print(f"Error: Input directory not found at {input_dir}")
            return
            
        output_dir.mkdir(parents=True, exist_ok=True)
        
        pdf_files = list(input_dir.glob("*.pdf"))
        
        if not pdf_files:
            print(f"No PDF files found in {input_dir}")
            return
        
        print(f"\nâœ¨ Found {len(pdf_files)} PDF files to process in {input_dir}")

        for pdf_path in pdf_files:
            self.process_pdf(pdf_path, output_dir)
            
        print("\nğŸ‰ All PDF files processed.")


if __name__ == "__main__":
    parser = argparse.ArgumentParser(
        description="Batch process PDF files using MinerU VLM with vLLM engine."
    )
    # ç¤ºä¾‹ç”¨æ³•ï¼špython process_pdfs.py --input_dir /path/to/pdfs --output_dir /path/to/output
    parser.add_argument(
        "--input_dir", 
        type=str, 
        required=True, 
        help="Path to the directory containing PDF files."
    )
    parser.add_argument(
        "--output_dir", 
        type=str, 
        required=True, 
        help="Path to the directory where output JSON files will be saved."
    )
    
    args = parser.parse_args()
    
    # å®ä¾‹åŒ–å¹¶è¿è¡Œ
    processor = MinerUPDFProcessor()
    processor.run_batch_processing(Path(args.input_dir), Path(args.output_dir))